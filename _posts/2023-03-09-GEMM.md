---
layout:     post
title:      GEMM
subtitle:   
date:       2023-03-09
author:     bjmsong
header-img: img/gemm/gemm.png
catalog: true
tags:

    - 并行计算
---

通用矩阵乘（GEMM）是深度学习中的主要的算子实现算法，例如，卷积，全连接，平均池化，注意力等算子均可以转换为 GEMM。

底层 GPU 和其他专有人工智能芯片 ASIC也针对矩阵乘的计算特点提供底层硬件计算单元的支持（例如 NVIDIA GPU 张量核（Tensor Core），Google TPU 脉动阵列的矩阵乘单元（Matrix Multiply Unit）等）。

因此优化GEMM的效率是一个重要的问题。

- how to optimize matrix multiply？下面是ChatGPT的回答：

  - Loop unrolling: Instead of looping through each element of the matrices, loop unrolling involves processing multiple elements in each loop iteration. This can reduce the overhead of looping and increase the efficiency of the multiplication.
  - Cache blocking: Matrix multiplication requires accessing data from memory, which can be slow. Cache blocking involves breaking the matrices into smaller submatrices that fit into the cache. This allows the processor to access the data more quickly and can improve performance.
  - SIMD instructions: Single Instruction Multiple Data (SIMD) instructions can be used to perform the same operation on multiple data elements at once. This can improve performance by reducing the number of instructions that need to be executed.
  - Parallelization: Matrix multiplication can be parallelized by dividing the matrices into smaller pieces and assigning each piece to a different processor or thread. This can reduce the overall computation time by allowing multiple computations to be performed simultaneously.
  - Algorithm optimization: There are several algorithms for matrix multiplication, such as Strassen's algorithm and the Coppersmith-Winograd algorithm, that have been developed to reduce the number of multiplications and additions required for large matrices. Implementing these algorithms can improve performance for larger matrices.

  Overall, the most effective optimization technique will depend on the specific characteristics of the matrices being multiplied and the hardware being used. A combination of these techniques may be necessary to achieve optimal performance.

GEMM优化的方法有很多，下面仅列举其中一些。



## 缓存

我们知道，当代计算机的CPU计算速度比内存的读取速度要快得多（即`von neumann bottleneck`），为了减少内存访问的影响，一个方法是引入缓存。

### 分块（tiling）

把矩阵分块，直到缓存可以容纳分块后的矩阵。例如2个128B\*128B\*128B的矩阵乘法运算，只需要访问一次内存，就可以在大小为512KB的缓存中完成。



### 空间访问局部性

`Cache line`（缓存行）是计算机处理器中的缓存中的基本单位，它是一块固定大小的内存块，通常是 64 字节。当处理器需要访问一个内存地址时，它会首先检查缓存中是否存在该内存地址的缓存行。

如果缓存中已经存在该缓存行，则处理器可以直接从缓存中读取数据，这比从内存中读取数据要快得多。如果缓存中不存在该缓存行，则处理器需要从内存中读取整个缓存行，并将其存储到缓存中。

`M*L`的矩阵`A`和`L*N`的矩阵`B`进行矩阵乘法，常规的过程如下：

```c++
    for (uint64_t i = 0; i < M; i++)
        for (uint64_t j = 0; j < N; j++) {
            float accum = 0;
	    for (uint64_t k = 0; k < L; k++)
                accum += A[i*L+k]*B[k*N+j];
	    C[i*N+j] = accum;
	}
```

存在一个问题：对于矩阵B，第k次访问的是位置是(k,j)，第k+1次访问的是位置是(k+1,j)（如下左图），也就是每次访问都是跨行的。因为元素是按行主序存放在内存中的，下一个访问的元素跟之前访问的元素间隔太远，很有可能不在一个`Cache line`里面，因此需要重新访问内存，这样降低了效率。

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/gemm/1.png) 
</li> 
</ul> 

为了解决这个问题，可以把矩阵B进行转置，计算过程如下，这样对矩阵B每次访问的元素都是相邻的（如上图右）。

```c++
    for (uint64_t k = 0; k < L; k++)
        for (uint64_t j = 0; j < N; j++)
            Bt[j*L+k] = B[k*N+j];

	for (uint64_t i = 0; i < M; i++)
        for (uint64_t j = 0; j < N; j++) {
            float accum = 0;
            for (uint64_t k = 0; k < L; k++)
                accum += A[i*L+k]*Bt[j*L+k];
            C[i*N+j] = accum;
	    }
```



## 多线程/OpenMP

```c++
    \#pragma omp parallel for collapse(2)
    for (uint64_t i = 0; i < M; i++)
        for (uint64_t j = 0; j < N; j++) {
            for (uint64_t k = 0; k < L; k++)
                C[i*N+j] += A[i*L+k]*Bt[j*L+k];
	    }
```



## Avoid False Sharing

多核场景下，每个核都一个自己的L1-cache（如下图）。多线程程序如果要同时修改在同一个`Cache line`里面的数据，会导致其它核的cache数据失效，其它核也需要重新从主存读取数据，这就叫做`false sharing`。

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/gemm/2.png) 
</li> 
</ul> 

避免`false sharing`的方法，就是不要频繁修改`cache line`里面的数据，尽量使用中间变量来存储中间结果。

```c++
    \#pragma omp parallel for collapse(2)
    for (uint64_t i = 0; i < M; i++)
        for (uint64_t j = 0; j < N; j++) {
            float accum = 0;
            for (uint64_t k = 0; k < L; k++)
                accum += A[i*L+k]*Bt[j*L+k];
            C[i*N+j] = accum;
	    }
```



## SIMD

```c++
    \#pragma omp parallel for collapse(2)
    for (uint64_t i = 0; i <M; ++i)
        for (uint64_t j = 0; j < N; ++j){
            __m256 X = _mm256_setzero_ps();
            for (uint64_t k = 0; k < L; k+=8){
                const __m256 AV = _mm256_load_ps(A+i*L+k);
                const __m256 BV = _mm256_load_ps(B+j*L+k);
                X  = _mm256_fmadd_ps(AV,BV,X);
            }
            C[i*N+j] = hsum_avx(X);
        }
```



## 性能提升

可以看到，最原始的实现耗时3.85s，avx2的实现耗时45ms，速度提升了85倍！

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/gemm/3.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/gemm/4.png) 
</li> 
</ul> 


