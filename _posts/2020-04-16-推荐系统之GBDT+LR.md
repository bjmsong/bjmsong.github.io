---
layout:     post
title:      推荐系统之
subtitle:   GBDT+LR
date:       2020-04-16
author:     bjmsong
header-img: img/Recommendation System/th.jpg
catalog: true
tags:
    - 推荐系统
---
### 模型结构
<ul> 
<li markdown="1">
利用GBDT自动进行特征筛选和组合，进而生成新的feature vector，再把该feature vector当作logistic regression的模型输入，预测CTR
![]({{site.baseurl}}/img/Recommendation System/gbdt_lr/model.png) 
</li> 
</ul> 

- 具体过程是这样的：一个样本在输入GBDT的某一子树后，会根据每个节点的规则最终落入某一叶子节点，那么我们把该叶子节点置为1，其他叶子节点置为0，所有叶子节点组成的向量即形成了该棵树的特征向量，把GBDT所有子树的特征向量concatenate起来，即形成了后续LR输入的特征向量
- 在实践过程中，模型的缺陷也比较明显，相比FTRL，FM，NN等能够通过梯度下降训练的模型来说，GBDT缺乏online learning的能力，因此我们往往只能相隔一天甚至几天才能够update GBDT模型，势必影响模型的实效性

### 模型的实效性问题和更新策略
- GBDT的部分几天更新一次，而LR的部分进行准实时的更新，这无疑是很好的工程实践经验


### facebook的实时数据流架构
<ul> 
<li markdown="1">
为了实现模型的准实时训练，facebook专门介绍了其基于Scribe的数据流架构，文中称其为online data joiner
![]({{site.baseurl}}/img/Recommendation System/gbdt_lr/实时数据流架构.png) 
</li> 
</ul> 

- 该模块最重要的作用是准实时的把来自不同数据流的数据整合起来形成sample features，并最终与click数据进行join，形成完整的labeled sample。


### 降采样和模型校正
- 对于巨型互联网公司来说，为了控制数据规模，降低训练开销，降采样几乎是通用的手段，facebook实践了两种降采样的方法，uniform subsampling和 negative down sampling
    - uniform subsampling：对所有样本进行无差别的随机抽样
    - negative down sampling：保留全量正样本，对负样本进行降采样。除了提高训练效率外，负采样还直接解决了正负样本不均衡的问题
- 负采样带来的问题是CTR预估值的漂移，比如真实CTR是0.1%，进行0.01的负采样之后，CTR将会攀升到10%左右。而为了进行准确的竞价以及ROI预估等，CTR预估模型是要提供准确的有物理意义的CTR值的，因此在进行负采样后需要进行CTR的校正，使CTR模型的预估值的期望回到0.1%


### 参考资料
- Practical Lessons from Predicting Clicks on Ads at Facebook
- https://zhuanlan.zhihu.com/p/57987311