---
layout:     post
title:      统计学习方法之二
subtitle:   统计学习及监督学习概论
date:       2019-11-17
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习本
---
>本文将介绍统计学习及监督学习概论

- **统计学习（statistical learning）**

  - **定义：计算机基于数据构建概率统计模型，运用模型对数据进行预测与分析的学科**

  - 基本假设：同类数据具有一定的统计规律性

  - 步骤：

    - 得到一个有限的训练数据集合
    
    - 确定包含所有可能的模型的假设空间，即学习模型的集合，输入空间到输出空间映射的集合
    
    - 确定模型选择的准则，即学习的策略
    
  - 实现求解最优模型的算法，及学习的算法
    
    - 通过学习方法选择最优模型
    
    - 利用学习的最优模型对新数据进行预测或分析
    
      
    

- 统计学习的分类

  - 基本分类
    - 监督学习（supervised learning）
      - 从标注数据中学习预测模型，标注数据表示输入和输出的对应关系
      - 每个具体的输入是一个实例，通常由特征向量表示
      - 监督学习假设输入与输出变量X和Y遵循联合概率分布P(X,Y)。P(X,Y)表示分布函数，或分布密度函数。训练数据和测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的
    - **无监督学习**（unsupervised learning）
      
      - 无标注数据
      - 本质：学习数据中的统计规律或潜在结构
    - **强化学习**（reinforcement learning）
      
      - 指智能系统在与环境的连续互动中学习最优行为策略
      
      - 假设智能系统与环境的互动基于**马尔可夫决策过程**，智能系统能观测到的是与环境互动得到的数据序列
      
      - 本质：学习最优的序贯决策
      
      - 智能系统与环境的互动如图所示。在每一步t，智能系统从环境中观测到一个状态（state）$$s_t$$与一个奖励（reward）$$r_t$$，采取一个行动（action）$$a_t$$。环境根据智能系统选择的动作，决定下一步t+1的状态$$s_{t+1}$$与奖励$$r_{t+1}$$。要学习的策略表示为给定的状态下采取的行动。
      
      - **智能系统的目标不是短期奖励最大化，而是长期积累奖励的最大化​**
      
        <ul> 
        <li markdown="1"> 
        ![]({{site.baseurl}}/img/rl/四要素.png) 
        </li> 
        </ul> 
      
      - 强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，由五元组<S,A,P,r,$$\gamma$$>组成：
      
        - S是有限状态的集合
      
        - A是有限动作的集合
      
        - P是状态转移概率（transition probability）函数：
      
          $$P(s'|s,a)=P(s_{t+1}=s'|s_t=s,a_t=a)$$
      
        - r是奖励函数：
        
          $$r(s,a)=E(r_{t+1}|s_t=s,a_t=a)$$
      
        - $$\gamma$$是衰减系数（discount factor）：$$\gamma\in[0,1]$$
      
    - 马尔可夫决策过程具有马尔可夫性，下一个状态只依赖于前一个状态与动作
      
    - 半监督学习（semi-supervised learning）
      - 少量标注数据，大量未标注数据
      - 利用未标注数据中的信息，辅助标注数据，进行监督学习
    - 主动学习（active learning）
      - 机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型
      - 目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果
    
  - **按模型分类**（？）
    
    - **概率模型和非概率模型**
      - 区别：模型的内在结构
        - 概率模型：一定可以表示为联合概率分布的形式，非概率模型不一定存在这样的联合概率分布
        - 条件概率分布P（y|x）和函数y=f(x)可以相互转化，条件概率分布最大化后得到函数，函数归一化后得到条件概率分布
      - 概率模型：概率图模型（朴素贝叶斯、隐马尔可夫、条件随机场）、决策树、概率潜在语义分析、潜在迪利克雷分配、高斯混合
      - 非概率模型：感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析、神经网络
    - 线性模型和非线性模型
      - 线性模型：函数是线性函数，感知机、线性支持向量机、k近邻、k均值、潜在语义分析
      - 非线性模型：核函数支持向量机、AdaBoost、神经网络、深度学习
    - **参数化模型和非参数化模型**
      - 参数化模型：假设模型参数的维度固定
      - 非参数化模型：假设模型参数的维度不固定或者无穷大，随着训练数据量的增加而不断增大
    
  - 按算法分类
    - **在线学习（online learning）**
      - 每次接受一个样本，进行预测，之后学习模型，并不断重复该操作
      - 随机梯度下降
    - 批量学习（batch learning）
      - 一次接受所有数据，学习模型，之后进行预测
    
  - 按技巧分类
    - **贝叶斯学习**
      - 利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率
      - 贝叶斯学派vs频率学派
    - **核方法**
      - 

- **统计学习方法三要素**

  - 模型
    - 所要学习的条件概率分布或决策函数
  - 策略
    - 按照什么样的准则学习或选择最优的模型
    - **损失函数**：度量一次模型预测的好坏
      - 分类问题
        - 0-1损失
        - 对数损失
        - 交叉熵？
      - 回归问题
        - 平方损失
        - 绝对损失
      - any more ？ 
    - 风险函数：度量平均意义下模型预测的好坏
      - 经验风险：模型关于训练数据集的平均损失
      - 结构风险：在经验风险上加上表示模型复杂度的正则化项
  - 算法
    - 

- 模型评估与模型选择

  - 训练误差与测试误差
  - 过拟合与模型选择

- 正则化与交叉验证

  - 正则化
  - 交叉验证

- 泛化能力

  - 泛化误差
  - 泛化误差上界

- 生成模型与判别模型

- 监督学习应用

  - 分类问题
    - 输出变量为有限个离散变量
  - 标注问题
    - 输入变量与输出变量均为变量序列
  - 回归问题
    - 输出变量为连续变量


