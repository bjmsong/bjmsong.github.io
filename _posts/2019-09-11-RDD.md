---
layout:     post
title:      RDD
subtitle:   
date:       2019-09-11
author:     bjmsong
header-img: img/spark/Spark_logo.png
catalog: true
tags:
    - Spark
---

> 本文将介绍spark的基本数据结构RDD

>RDD: a fault-tolerant collection of elements that can be operated on in parallel

RDD,即弹性分布式数据集,Spark2.0之前，RDD是主要的数据接口，2.0之后，Dataset在RDD基础上，加入了更多的优化，从而取代了RDD。

### RDD的创建
- 可以从现有的集合创建
```
val data = Array(1, 2, 3, 4, 5)
val distData = sc.parallelize(data)
```
- 也可以读取外部数据创建
```
val distFile = sc.textFile("data.txt")
```
读取的路径可以是文件、文件夹、压缩文件等

### RDD的操作
[RDD操作API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD)
RDD有两种种操作类型：
- 转换操作（Transformation）： 从已有RDD转换成新的RDD。转换操作是**惰性操作**，只是定义一个RDD并记录依赖关系，没有立即执行，只有遇到行动操作才会触发。
[RDD转换操作算子解释](https://www.cnblogs.com/MOBIN/p/5373256.html)
- 行动操作（Action）：对RDD进行计算，并返回结果到driver。
[RDD行动操作算子解释](https://www.cnblogs.com/MOBIN/p/5414490.html)

#### 函数传递
1. 匿名函数：当函数代码比较短
2. 单例对象中的静态方法

```
object MyFunctions {
  def func1(s: String): String = { ... }
}

myRdd.map(MyFunctions.func1)
```

- 也可以调用类方法，稍微麻烦点

#### 闭包(closure)
闭包指的是操作RDD时，所有executor可见的变量和方法。闭包会被序列化，然后发送到各个executor。
因此，driver端的变量并不会被改变！
```
var counter = 0
var rdd = sc.parallelize(data)

// Wrong: Don't do this!!
rdd.foreach(x => counter += x)

println("Counter value: " + counter)
```
counter是driver端的变量，集群模式下，发送到executor的是counter的拷贝，dirver端的counter并不会改变。
这种场景下，可以使用**累加器(Accumulator)**改变全局变量的值。
明白了闭包的概念，就可以明白，当
```
rdd.foreach(println)
```
只会print到executor的stdout，如果需要print到driver端，需要先take或者collect
```
rdd.take(100).foreach(println)
```

#### PairRDD
- RDD[(key,value)]
[PairRDD操作API](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.PairRDDFunctions)
[PairRDD操作算子解释](https://www.cnblogs.com/MOBIN/p/5384543.html#9)

#### Shuffle操作
有些对RDD的操作会引起shuffle，即数据的重新分区，shuffle是非常消耗资源，影响性能的。
容易引起shuffle操作的算子有：
- repartition，coalesce
- ByKey operations (except for counting) like groupByKey and reduceByKey
- join operations

#### RDD的持久化
经常使用的RDD可以通过持久化的方式缓存到内存中

[Spark性能优化对持久化的介绍](https://bjmsong.github.io/2019/09/03/Spark%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98/)

### 共享变量 
>share these kind of variable among the executors

上面介绍了闭包，我们知道spark会将变量拷贝、分发到各个executor，并且executor上对变量的操作不会返回到driver端。为了对实际应用场景进行优化，spark提供了两种类型的共享变量：Broadcast和Accumulator。
- 广播变量(Broadcast)
广播变量会在每台机器上存储一份拷贝，这样就不需要在每个task中传输变量，可以减少网络传输的性能开销，并减少对Executor内存的占用开销。
[广播变量在Spark性能优化中的妙用](https://bjmsong.github.io/2019/09/03/Spark%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E8%B0%83%E4%BC%98/)
- 累加器(Accumulator)
safely updating a variable when execution is split up across worker nodes in a cluster. only the dirver program can read the accumulator's value 

```
scala> val accum = sc.longAccumulator("My Accumulator")
accum: org.apache.spark.util.LongAccumulator = LongAccumulator(id: 0, name: Some(My Accumulator), value: 0)

scala> sc.parallelize(Array(1, 2, 3, 4)).foreach(x => accum.add(x))

scala> accum.value
res2: Long = 10
```

### 其它关于RDD的
#### RDD的分区(partition)
RDD的分区是一个逻辑概念，转换操作前后的分区在物理上可能是同一块内存或者存储。在RDD操作中用户可以设定和获取分区数目，默认分区数目为该程序所分配到的cpu核数，如果是从HDFS文件创建，默认为文件的分片数。

#### RDD的“血统”
<ul> 
<li markdown="1"> 
![RDD的血统]({{site.baseurl}}/img/spark/RDD/RDD的血统.png) 
</li> 
</ul> 


“血统”和依赖关系：RDD的容错机制是通过记录更新来实现的，且记录的是粗粒度的转换操作。我们将记录的信息称为血统（Lineage）关系，而到了源码级别，Apache Spark 记录的则是 RDD 之间的依赖（Dependency）关系。如上所示，每次转换操作产生一个新的RDD（子RDD），子RDD会记录其父RDD的信息以及相关的依赖关系。　

falut tolerance：任何partition丢失了，都可以从头恢复

#### RDD的依赖关系
<ul> 
<li markdown="1"> 
![窄依赖宽依赖]({{site.baseurl}}/img/spark/RDD/窄依赖宽依赖.png) 
</li> 
</ul> 

- 窄依赖：父RDD的每个分区只被子RDD的一个分区所使用，子RDD的任务可以跟父RDD在同一个Executor一起执行，不需要经过 Shuffle 阶段去重组数据。
	- map、filter、union、join with inputs co-partitioned(父RDD hash-partitioned),mapPartitions,mapValues
- 宽依赖：父RDD的每个分区被子RDD的多个分区所使用，父 RDD 与子 RDD 之间存在着 Shuffle 过程。
	- groupByKey、join with inputs not co-partitioned（父RDD 不是 hash-partitioned)
- 窄依赖对优化有利：
  宽依赖对应shuffle操作，开销大
  当RDD分区丢失时，窄依赖只需要计算和子RDD分区对应的父RDD分区即可，宽依赖要计算多个父RDD分区，甚至是全部分区            


### 参考资料
- https://spark.apache.org/docs/latest/rdd-programming-guide.html
- https://cloud.tencent.com/developer/article/1004889
