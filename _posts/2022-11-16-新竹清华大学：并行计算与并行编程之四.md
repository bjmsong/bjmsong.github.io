---
layout:     post
title:      新竹清华大学：并行计算与并行编程
subtitle:   Part IV Distributed Computing Frameworks
date:       2022-11-16
author:     bjmsong
header-img: 
catalog: true
tags:
    - 并行计算
---
## 十二: Distributed Computing Framework for Big Data: MapReduce(Haddop)
### Big Data

### MapReduce
- google开发(2004年)，但是没有开源
- Program written in this functional style are automatically parallelized and executed on machines
- yahoo/开源社区实现并开源了Hadoop(Java)
- MapReduce has several meanings
  - A programming model
  - A implementation
  - A system architecture
- Typical Large-Data Problem Solution
1. Iterate over a large number of records
2. Extract something of interest from each record -- Map
3. Shuffle and sort intermediate results
4. Aggregate intermediate results -- Reduce
5. Generate final output
- MapReduce Programming Model
  - 只需要用户完成map，reduce函数的实现，其余环节框架会搞定
  - Map: processes a key-value pair to generate a set of intermediate key-value pairs
  - Reduce: merges all intermediate values associated with the same intermediate key
- MapReduce "Runtime"
  - Handles scheduling
    - Assign workers to map and reduce tasks 
  - Handles data distribution
  - Handles synchronization
    - Gathers,sorts,and shuffles intermediate data
  - Handles errors and faults
    - Detects worker failures and re-run
  - Everything happens on top of a distributed File System
- Distributed File System
  - A node act as both compute and storage node
    - Store data on the local disks of nodes in the cluster
    - Start up the workers on the node that has the data local
      - 这样数据不需要经常从storage node搬到compute node
  - Hadoop： HDFS
    - File is partitioned into 64MB data chunks for scalability
    - Each data is replicated into 3 copies and placed on differernt datanodes for fail recovery
    - Only support append to avoid data inconsistency(数据一致性) problem    
- Full Picture
  - master node
    - namenode：管理文件系统
    - job submission node: 管理task
  - slave node
    - tasktracker: 执行task
    - datanode: 文件系统
- MapReduce in action
1. 切分数据(以64MB为单位)
2. map阶段：file system决定要启动几个map process(一个partition数据对应一个map process，尽量在数据的本地启动map process)
3. Reduce阶段：用户决定要几个reduce process，由hash function分配key到不同的reducer
- Summary
  - MapReduce is a simplified programming model which allows the user to quickly write and test distributed systems to handle data with huge volume
    - 不是所有问题都适合map-reduce的方式去解决，例如图的计算 
  - Its efficient and automatic distribution of data and workload across machines. Moving process to data.
  - Seamless scalability. after a MapReduce program is written and functioning on 10 nodes, very little work is required for making the same program 1000 nodes


### Hadoop Eco-system
- Hadoop
  - core services
    - MapReduce: Computaion
    - HDFS: Storage
    - YARN: Resource Manager
- Hive: 提供类sql语句处理数据
- NoSQL Database: HBase
- Storm: 流式数据
- ...

### Hadoop Programming




## 十三: In-Memory Computing Spark
### Motivation: Iterative and Iteractive Computation
- Motivation
  - Data reuse is frequent in iterative(迭代) and interactive(交互) data processing
    - map-reduce不适合，因为需要反复跟disk交互数据，很慢
    - 如果把数据放在memory，会快很多
  - MapReduce only support acyclic workflow
- Objective
  - Utilize DSM(Distributed Shared Memory) in data processing to enable in-memory computing
  - Allow users to explicitly cached dataset in memory across machines and reuse it in multiple MapReduce-like parallel operations
  - Retain the scalability and fault tolerance property like MapReduce
- Spark introduces an data abstraction called Resilient(fault tolerance) Distributed Dataset(RDD)
  - RDD is a read-only collection of objects partitioned across a set of machines
    - 为了解决scalability的问题
    - RDD可以通过transform转换成新的RDD，但不会覆盖原来的RDD
  - RDD can be rebuilt if a partition is lost using the "lineage（血统）" technique
    - lineage: 把RDD转换的过程都记录下来
- Spark is integrated into a general programming language called "Scala"
  - Pure-bred O.O language: every variable / dataset is an object and every operation is a method-call
  - Seamless Java interpreter


### Scala: Functional Programming
- Scala: Scalable Language
- Immutable data + function = Functional Programming
  - function: 专指数学函数，输出只跟输入有关，跟系统状态无关
    - referential transparency: the output value of a function depends only on the arguments that are input to the function
    - function之间没有依赖
- Languages: Haskell, Scala, Lisp, Scheme
- Order of evaluation is usually undefined  
- Good fit for parallel execution

### Spark: Data & Computation Management
- 


### 参考资料
- google
  - 《The Google File System》
  - 《MapReduce: Simplified Data Processing on Large Clusters》
  - 《Bigtable: A Distributed Storage System for Structured Data》
- 《Spark: Low Latency, Massively Parallel Processing Framework》
- MPI vs Hadoop vs Spark
https://extendswind.top/posts/technical/mpi_hadoop_spark_comparing/