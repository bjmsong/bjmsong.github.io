---
layout:     post
title:      python爬虫
subtitle:   
date:       2020-03-24
author:     bjmsong
header-img: img/language/爬虫.png
catalog: true
tags:
    - python
---

> 爬虫：一段自动抓取互联网信息的程序，从互联网上抓取对于我们有价值的信息



### Python爬虫架构

**Python 爬虫架构主要由五个部分组成，分别是调度器、URL管理器、网页下载器、网页解析器、应用程序（爬取的有价值数据）**

- 调度器：相当于一台电脑的CPU，主要负责调度URL管理器、下载器、解析器之间的协调工作。
- URL管理器：包括待爬取的URL地址和已爬取的URL地址，防止重复抓取URL和循环抓取URL，实现URL管理器主要用三种方式，通过内存、数据库、缓存数据库来实现。
- 网页下载器：通过传入一个URL地址来下载网页，将网页转换成一个字符串，网页下载器有`urllib2`（Python官方基础模块）包括需要登录、代理、和cookie，`requests`(第三方包)
- 网页解析器：将一个网页字符串进行解析，可以按照我们的要求来提取出我们有用的信息，也可以根据DOM树的解析方式来解析。网页解析器有:
  - 正则表达式（直观，将网页转成字符串通过模糊匹配的方式来提取有价值的信息，当文档比较复杂的时候，该方法提取数据的时候就会非常的困难）
  - `html.parser`（Python自带的）
  - `beautifulsoup`（第三方插件，可以使用Python自带的html.parser进行解析，也可以使用lxml进行解析，相对于其他几种来说要强大一些）
  - lxml（第三方插件，可以解析 xml 和 HTML）
  - html.parser 和 beautifulsoup 以及 lxml 都是以 DOM 树的方式进行解析的。
- 应用程序：就是从网页中提取的有用数据组成的一个应用。



<ul> 
<li markdown="1"> 
下面用一个图来解释一下调度器是如何协调工作的:
![]({{site.baseurl}}/img/language/调度器.png) 
</li> 
</ul> 





### urllib2 实现下载网页的三种方式

```python
#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
import cookielib
import urllib2
 
url = "http://www.baidu.com"
response1 = urllib2.urlopen(url)
print "第一种方法"
#获取状态码，200表示成功
print response1.getcode()
#获取网页内容的长度
print len(response1.read())
 
print "第二种方法"
request = urllib2.Request(url)      # 参数 data：可以传入用户名/密码
# 请求伪装成Mozilla浏览器，可以模拟浏览器发送GET请求
request.add_header("user-agent","Mozilla/5.0")
response2 = urllib2.urlopen(request)
print response2.getcode()
print len(response2.read())
 
print "第三种方法"
cookie = cookielib.CookieJar()
#加入urllib2处理cookie的能力
opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))
urllib2.install_opener(opener)
response3 = urllib2.urlopen(url)
print response3.getcode()
print len(response3.read())
print cookie
```



### 账号密码登录

```python
from urllib import request, parse
# 动态网页，以post发送请求，参数data以bytes形式传入
print('Login to weibo.cn...')
email = input('Email: ')
passwd = input('Password: ')
login_data = parse.urlencode([
    ('username', email),
    ('password', passwd),
    ('entry', 'mweibo'),
    ('client_id', ''),
    ('savestate', '1'),
    ('ec', ''),
    ('pagerefer', 'https://passport.weibo.cn/signin/welcome?entry=mweibo&r=http%3A%2F%2Fm.weibo.cn%2F')
])

req = request.Request('https://passport.weibo.cn/sso/login')
req.add_header('Origin', 'https://passport.weibo.cn')
req.add_header('User-Agent',
               'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25')
req.add_header('Referer',
               'https://passport.weibo.cn/signin/login?entry=mweibo&res=wel&wm=3349&r=http%3A%2F%2Fm.weibo.cn%2F')

with request.urlopen(req, data=login_data.encode('utf-8')) as f:
    print('Status:', f.status, f.reason)
    for k, v in f.getheaders():
        print('%s: %s' % (k, v))
    print('Data:', f.read().decode('utf-8'))
```





### 使用 Beautiful Soup 解析 html 文件

```python
#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
import re
 
from bs4 import BeautifulSoup
html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>
<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
and they lived at the bottom of a well.</p>
<p class="story">...</p>
"""
#创建一个BeautifulSoup解析对象
soup = BeautifulSoup(html_doc,"html.parser",from_encoding="utf-8")
#获取所有的链接
links = soup.find_all('a')
print "所有的链接"
for link in links:
    print link.name,link['href'],link.get_text()
 
print "获取特定的URL地址"
link_node = soup.find('a',href="http://example.com/elsie")
print link_node.name,link_node['href'],link_node['class'],link_node.get_text()
 
print "正则表达式匹配"
link_node = soup.find('a',href=re.compile(r"ti"))
print link_node.name,link_node['href'],link_node['class'],link_node.get_text()
 
print "获取P段落的文字"
p_node = soup.find('p',class_='story')
print p_node.name,p_node['class'],p_node.get_text()
```





```python
# 如果还需要更复杂的控制，比如通过一个Proxy去访问网站，我们需要利用ProxyHandler来处理
proxy_handler = urllib.request.ProxyHandler({'http': 'http://www.example.com:3128/'})
proxy_auth_handler = urllib.request.ProxyBasicAuthHandler()
proxy_auth_handler.add_password('realm', 'host', 'username', 'password')
opener = urllib.request.build_opener(proxy_handler, proxy_auth_handler)
with opener.open('http://www.example.com/login.html') as f:
    pass

# 其它
def get_content(url):
    '''
    模仿浏览器，提交请求，获取http响应
    '''
    opener = request.build_opener()
    # 标识浏览器
    opener.addheaders = [('User-Agent',
                          'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.47 Safari/537.36')]
    # cookie
    opener.addheaders.append(('Cookie',
                              'cookie_locale=zh; UM_distinctid=15ba3242e791001-0ea5b4e3364b28-4e47052e-232800-15ba3242e7aaff; WtbB_2132_saltkey=INutSKKa; WtbB_2132_lastvisit=1494571257; WtbB_2132_ulastactivity=4216TyHziXRs0dIjw08lGH6z2H40m%2FqPGkdmdAvNJLtmZXQxb74V; WtbB_2132_nofavfid=1; __utma=75570051.169882094.1491626208.1494574858.1494574858.1; __utmz=75570051.1494574858.1.1.utmcsr=apidoc.datayes.com|utmccn=(referral)|utmcmd=referral|utmcct=/app/overview; cloud-sso-token=5A63AFA2791C25117EEDC8D804E9E49C; CNZZDATA1000377076=757399342-1495001413-https%253A%252F%252Fapp.wmcloud.com%252F%7C1495761965; _gat=1; _ga=GA1.2.169882094.1491626208; _gid=GA1.2.437948554.1495787959'))
    f = opener.open(url)
    content = f.read()
    return content.decode('utf-8')


url = ''
content = get_content(url)
```



### 学习资料

- https://www.runoob.com/w3cnote/python-spider-intro.html
- https://www.jianshu.com/p/e320add10e33
- https://www.runoob.com/w3cnote/scrapy-detail.html
- https://cuiqingcai.com/927.html
- https://www.zhihu.com/question/20899988
- https://www.cnblogs.com/dreamer-fish/p/5484767.html
- https://www.jianshu.com/p/87d1e2f875b7
- https://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&mid=2650690746&idx=1&sn=290ec1db66c9a62018e16b056ca83f21&chksm=bea6256989d1ac7f7c1a65c84e45a822645a83ec4591522784af048e9c0d9e31f2ebd52be2ba&mpshare=1&scene=1&srcid=1112CSRPgPbngk4kfS5aP9PK#rd
- https://www.cnblogs.com/cocoajin/p/3679821.html

