---
layout:     post
title:      推荐系统三十六式之
subtitle:   Netflix推荐架构
date:       2020-04-20
author:     bjmsong
header-img: img/Recommendation System/th.jpg
catalog: true
tags:
    - 推荐系统
---

- **工程实现才是推荐系统的骨架**
- 一个好的推荐系统不仅仅是在线下模型评测指标多么好，也不仅仅是在某个时刻像是灵光乍现一样击中了用户某个口味，而是随着用户的不断使用，产品和用户一起变好，产品背后的人得到进步，用户也越来越喜欢产品
- 好的推荐系统架构
    - 实时响应需求
    - 及时、准确、全面记录用户反馈
    - 可以优雅降级
    - 快速试验多种策略



### Netflix 的推荐系统架构

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/Recommendation System/36/Netflix 的推荐系统架构.png) 
</li> 
</ul> 

- **离线层：不用实时数据，不提供实时服务**
- **近线层：使用实时数据，不保证实时服务**
- **在线层：使用实时数据，要保证实时服务**



#### 数据流

- 用户在产品UI上使用产品，消费展示的内容，产生行为事件数据，实时地被收集走，一边进入分布式的文件系统中存储，供离线阶段使用，另一边流向近线层的消息队列，供近线阶段的流计算使用
- 离线存储的全量数据被抽取出来，组成离线计算所需的训练数据，这些训练数据被一个管理数据生成和发布的组件统一管理，要使用数据的下游，比如模型训练会在离线数据生成时得到这个组件的通知，从而开始训练，训练得到的模型用于进一步为用户计算推荐结果
- 离线阶段的推荐结果或者模型在近线阶段被更新，进一步在在线阶段被直接使用，产生最终的推荐结果，呈现给用户



#### 在线层

- 在线层的触发时机是当用户发出请求，也就是用户进入一个推荐场景，推荐位等着展示推荐结果时，这个时候需要承担责任就是在线层。在线层就是实时响应用户请求
- 在线层的优势有：
    - 直接首次接触到大多数最新数据
    - 对用户请求时的上下文了如指掌
    - 只需计算必须的信息，不需要考虑所有的信息
- 在线层也有严格的制约：
    - 严格的服务响应时间，不能超时，或者让用户等太久
    - 服务要保证可用性，稳定性
    - 传输的数据有限
- 在线层常常展现出的形式就是`Rest API`形式，后端则通常是RPC服务内部互相调用，以用户 ID、场景信息去请求，通常就在 ms 响应时间内返回 Json 形式的推荐结果
- 哪些计算逻辑适合放在在线层
    - 简单的算法逻辑
    - 模型的预测阶段
    - 商业目标相关的过滤或者调权逻辑
    - 场景有关的一些逻辑
    - 互动性强的一些算法
- 在线阶段还要实时地分发用户事件数据，就是当用户不断使用产品过程产生的行为数据，需要实时地上报给有关模块。这一部分也是需要实时的，比如用于防重复推荐的过滤



#### 离线层

- 离线层就是躲在推荐系统的大后方，批量、周期性地执行一些计算任务
<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/Recommendation System/36/离线层.png) 
</li> 
</ul> 

- 离线阶段主要面对的数据源就是 Hadoop，实质上是 HDFS。收集到的所有日志都存在这里面，是一个全量的数据中心
- 通过 Pig 或者 Hive 等工具，从全量日志中按照算法要求抽取出不同的数据，再加上其他数据变成了不同算法所需的数据源
- 如果这种数据源比较多时，就需要有专门的工具统一管理起来，这个管理上要求：
    - 数据准备好之后及时通知相关方，也就是要有订阅发布的模式
    - 能够满足下游不同的存储系统
    - 完整的监控体系，并且监控过程对于数据使用方是透明的
- 在 Netflix 内部，承担这个管理任务的工具叫做`Hermes`，类似 Kafka，但是又有不同的内部工具。
- **离线阶段的任务主要是两类：模型训练和推荐结果计算**
- 离线阶段有以下这么几个好处
    - 可以处理最大的数据量；
    - 可进行批量处理和计算；
    - 不用有响应时间等要求
- 当然坏处也是明显的：
    - 无法及时响应前端需求；
    - 面对的数据较静态，无法及时反应用户的兴趣变化



#### 近线层

- 是一个非常重要的一层，它结合了离线层和在线层的好处，摒弃了两者的不足
- 数据来源是实时的行为事件队列，但是计算的结果并不是沿着输入数据的方向原路返回，而是进入了在线数据库中，得到用户真正发起请求时，再提供服务
- **一个典型的近线计算任务是这样的：从事件队列中获取最新的一个或少许几个用户反馈行为，首先将这些用户已经反馈过的物品从离线推荐结果中剔除，进一步，用这几个反馈行为作为样本，以小批量梯度下降的优化方法去更新融合模型的参数**
- 近线计算任务一个核心的组件就是流计算，因为它要处理的实时数据流
- 常用的流计算框架有 Storm，Spark Streaming，FLink 等
    - Netflix 采用的内部流计算框架 Manhattan，这和 Storm 类似
    - 略有区别的是 Spark Streaming，实际上并不是实时流计算，而是小批量计算



### 简化架构

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/Recommendation System/36/简化架构.png) 
</li> 
</ul> 

- 完全舍弃掉近线层
- **避免使用分布式系统**
    - 在一个新产品的场景下， 当数据量还没有那么大时，使用分布式存储或者计算框架，非常不划算
    - 如果性能不足，请升级单机配置。根据经验，一个几千万用户，几十万到百万的物品的协同过滤或者矩阵分解，如果充分发挥单机的性能，综合效率会远远优于在 Spark 上运行


<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/Recommendation System/36/各层对比.png) 
</li> 
</ul> 



### 参考资料

- Beyond the 5 stars（Netflix Recommendations）
    - Netflix 详细宏观上介绍了自家推荐系统的产品形态，不只是比赛中的评分预测那么简单的
- System Architectures for Personalization and Recommendation
    - Netflix 推荐系统的架构介绍