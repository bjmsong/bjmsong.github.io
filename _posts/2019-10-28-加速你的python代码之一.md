---
layout:     post
title:      加速你的python代码之一
subtitle:   向量化
date:       2019-10-28
author:     bjmsong
header-img: img/python.jpg
catalog: true
tags:
    - python
---
>python是处理数据的利器，然而在面对一些比较大的数据集时，python有时会感觉运行很慢，这大大影响了工作的效率。那么有哪些方法可以提升python的效率呢，下面就来介绍几种方法，抛砖引玉。



## 向量化

当我们要进行向量间的运算，比如矩阵乘法时。常规的做法是需要用for循环去遍历向量里面的每一个值
```
import numpy as np
import time
# Number of features
n = 1000
# Number of training examples
m = 10000
# Initialize X and W
X = np.random.rand(n,m)
W = np.random.rand(n,1)

# Non Vectorized code
Z1 = np.zeros((1,m))
t2 = time.time()
for i in range(X.shape[1]):
    for j in range(X.shape[0]):
        Z[0][i] += W[j]*X[j][i]
print("Time taken for non vectorized code is : ",(time.time()-t2)*1000,"ms")
```
python的向量化可以帮助我们高效地实现这个过程
```
# Vectorized code
t1=time.time()
Z = np.dot(W.T,X)
print("Time taken for vectorized code is : ",(time.time()-t1)*1000,"ms")
```



## 拒绝for循环

### 一个典型的for循环
```
import seaborn as sns
import numpy as np
import pandas as pd
import time

data = sns.load_dataset('iris')

def compute_class(petal_length):
    if petal_length <= 2:
        return 1
    elif 2 < petal_length < 5:
        return 2
    else:
        return 3

# for loop
start = time.time()

class_list = list()
for i in range(len(data)):
    petal_length = data.iloc[i]['petal_length']
    class_num = compute_class(petal_length)
    class_list.append(class_num)

end = time.time()
print("For-loop run time = {}".format(end - start))
```



### iterrows方法

for循环是非常耗时的，因此需要想办法抛弃掉for循环。可以采用.iterrows()方法，该方法实现了一个生成器函数，它将在每次迭代中生成一行数据，缺点是iterrows()不能保留行之间的dtype。
```
start = time.time()
class_list = list()
for index, data_row in data.iterrows():
    petal_length = data_row['petal_length']
    class_num = compute_class(petal_length)
    class_list.append(class_num)

end = time.time()
print("Iterrows run time = {}".format(end - start))
```



### apply是更优方案

apply本身并不快，但与DataFrame结合使用时，它具有很大的优势。这取决于apply表达式的内容。如果它可以在Cython中执行，那么apply要快得多。
```
start = time.time()
class_list = data.apply(lambda row: compute_class(row['petal_length']), axis=1)
end = time.time()
print("apply() run time = {}".format(end - start))
```



### 使用内置的函数来替代循环的语句

```
start = time.time()
class_list = pd.cut(x=data.petal_length, bins=[0, 2, 5, 100], include_lowest=True, labels=[1, 2, 3]).astype(int)
end = time.time()
print("cut() run time = {}".format(end - start))
```



### pandas向量化

需要改写计算的函数，将series作为输入
```
def compute_class(series):
    data['class'] = 3
    data.loc[series <= 2, 'class'] = 1
    data.loc[(series < 5) & (series > 2), 'class'] = 2

start = time.time()
compute_class(data["petal_length"])
end = time.time()
print("pandas vectorization  run time = {}".format(end - start))
```



### numpy向量化

Numpy array会更快
```
start = time.time()
compute_class(data["petal_length"].values)
end = time.time()
print("numpy vectorization  run time = {}".format(end - start))
```



## 比apply再快10倍

```
np.random.seed(0)
N = 10**5
A_list = np.random.randint(1, 100, N)
B_list = np.random.randint(1, 100, N)
df = pd.DataFrame({'A': A_list, 'B': B_list})

%timeit list(map(divide, df['A'], df['B']))                                   # 43.9 ms
%timeit np.vectorize(divide)(df['A'], df['B'])                                # 48.1 ms
%timeit [divide(a, b) for a, b in zip(df['A'], df['B'])]                      # 49.4 ms
%timeit [divide(a, b) for a, b in df[['A', 'B']].itertuples(index=False)]     # 112 ms
%timeit df.apply(lambda row: divide(*row), axis=1, raw=True)                  # 760 ms
%timeit df.apply(lambda row: divide(row['A'], row['B']), axis=1)              # 4.83 s
%timeit [divide(row['A'], row['B']) for _, row in df[['A', 'B']].iterrows()]  # 11.6 s
```

- 基于tuple的方法（前四个）要远快于基于Series的方法（后三个）
- apply方法设置raw=True，可以大大改善性能


np.vectorize：可以比上面案例中的for循环提升百倍以上性能
```
start = time.time()
np.vectorize(compute_class)(data["petal_length"])
end = time.time()
print("np.vectorize  run time = {}".format(end - start))
```



## numba：就像坐上了火箭

numba是一个用于编译Python数组和数值计算函数的编译器，这个编译器能够大幅提高直接使用Python编写的函数的运算速度。

numba使用LLVM编译器架构将纯Python代码生成优化过的机器码，通过一些添加简单的注解，将面向数组和使用大量数学的python代码优化到与c，c++和Fortran类似的性能，而无需改变Python的解释器。
```
from numba import njit

# 在jit装饰器装饰的函数中，不可以有第三方的package
@njit
def divide(a, b):
    res = np.empty(a.shape)
    for i in range(len(a)):
        if b[i] != 0:
            res[i] = a[i] / b[i]
        else:
            res[i] = 0
    return res

%timeit divide(df['A'].values, df['B'].values)  # 717 µs
```



## Modin

通过在**系统所有可用的 CPU 核上**自动分配计算来加速 pandas。有了它，对于任何尺寸的 pandas 数据数据集，Modin 声称能够以 CPU 内核的数量得到近乎线性的加速。



## 用C重写关键计算部分





## 参考资料

- https://stackoverflow.com/questions/52673285/performance-of-pandas-apply-vs-np-vectorize-to-create-new-column-from-existing-c
- https://towardsdatascience.com/how-to-make-your-pandas-loop-71-803-times-faster-805030df4f06
- https://juejin.im/post/5c62bb92e51d45407f057b45
