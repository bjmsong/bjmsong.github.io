---
layout:     post
title:      统计学习方法之三
subtitle:   感知机
date:       2019-11-30
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---
>感知机学习旨在求出将训练数据进行线性划分的分离超平面。感知机1957年由Rosenblatt提出，是神经网络与支持向量机的基础。



### 模型

$$f(x)=sign(w*x+b)$$

- 线性分类模型，属于判别模型

- 假设空间是定义在特征空间中的所有线性分类模型

- 几何解释：线性方程

  $$w*x+b=0$$

  对应于一个超平面S，这个超平面将特征空间划分为两个部分。



### 学习策略

- 损失函数：误分类点到超平面S的总距离

  $$L(w,b)=-\sum_{x_i\in{M}}{y_i(w*x_i+b)}$$

  M是误分类点的集合



### 学习算法

- 原始形式

  1. 选取初值$$w_0,b_0$$

  2. 在训练集中选取数据（$$x_i,y_i$$）

  3. 如果$$y_i(w*x_i+b)<=0$$（误分类点）,则对w，b进行更新

     $$w \leftarrow w+\eta y_ix_i$$

     $$b \leftarrow b+\eta y_i$$

     $$\eta 是学习率$$

  4. 转至2，直至训练集中没有误分类点，或者满足误差要求

  - 梯度推导

    $$\nabla_wL(w,b)=-\sum_{x_i\in{M}}{y_ix_i}$$

    $$\nabla_bL(w,b)=-\sum_{x_i\in{M}}{y_i}$$

- 对偶形式

  - 将w和b表示为实例$$x_i$$和标记$$y_i$$的线性组合的形式，通过求解其系数而求得w和b

    1. $$\alpha_i \leftarrow 0, b \leftarrow 0$$

    2. 在训练集中选取数据$$(x_i,y_i)$$

    3. 如果$$y_i(\sum_{j=1}^{N}{a_jy_jx_j*x_i}+b)<=0$$

       $$\alpha \leftarrow \alpha+\eta $$

       $$b \leftarrow b+\eta y_i$$

    4. 转至2，直至训练集中没有误分类点，或者满足误差要求



### 代码实现



