---
layout:     post
title:      【笔记】关于机器学习，你必须知道的
subtitle:   
date:       2019-09-27
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---
>最近读了《A Few Useful Things to Know about Machine Learning》， 这篇paper主要谈到了开发机器学习应用时需要关注的一些关键问题。

### 1.Learning = Representation+Evaluation+Optimization
很多机器学习书会按照算法一个个讲，这样给初学者的认知就是机器学习就是这么一个个算法组成的。算法的数量浩如烟海，很容易让人觉得困惑，在碰到实际问题时究竟用什么模型。这些算法之间的联系又在哪里。
因此，paper的第一条，穿透现象看本质，告诉我们学习算法是由三部分组成的：模型（Representation），评估（Evaluation），优化算法（Optimization）。
>李航老师的《统计学习方法》里面分成了模型、策略和算法。

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/The three components of learning algorithms..png) 
</li> 
</ul> 

### 2.It’S Generalization That Counts
>（训练集）死记硬背是容易的，真正考试考高分是不容易的（泛化能力）

机器学习最根本的目标是在训练数据以外的数据上取得不错的泛化效果。这是因为，无论我们的训练数据集有多么庞大，都不可能涵盖所有的可能性。机器学习初学者的常见错误，就是在训练集上做验证，这就会引起过拟合。
比较好的做法是将数据分成训练集/验证集/测试集，如果训练数据数量较少，可做交叉验证，但如果数据和时间相关，最好还是按时间线切分数据。

### 3.Data Alone is Not Enough
>NFL(no free lunch):在不考虑具体问题的情况下，没有任何一个算法比另一个算法更优，甚至没有胡乱猜测更好。



### 4.Overfitting has many faces


### 5.Intution Fails In High Dimensions


### 6.Theoretical Guarantees Are Not What They Seem


### 7.Feature Engineering is The Key


### 8.More Data Beats A Cleverer ALgorithms


### 9.Learn Many Models, Not Just One


### 10.Simplicity Does Not Imply Accuracy


### 11.Representable Does Not Imply Learnable


### 12.Correlation Does Not Imply Causation



### 参考资料
- 《No Free Lunch Theorems for Optimization》
- 《Simple Explanation of the No-Free-Lunch Theorem and Its Applications》
- https://baike.baidu.com/reference/259825/639fmRM84ug0Hv3NXYCUH6H0EroltQCAuK7s0TkAqWmx9Vpech3j_9KGquzfkJr45Qy1YszRKvbhBw