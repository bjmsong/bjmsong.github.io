---
layout:     post
title:      分布式机器学习
subtitle:   
date:       2022-09-23
author:     bjmsong
header-img: 
catalog: true
tags:
    - 分布式
---
## 整体脉络 https://zhuanlan.zhihu.com/p/533852982?utm_id=0
- 上古时代的分布式机器学习平台：MPI,Hadoop,Spark
- 参数服务器
- Pathways

## 《分布式机器学习》（刘铁岩）
https://zhuanlan.zhihu.com/p/377147020


## 《Dive into Big Model Training》
https://github.com/qhliu26/BM-Training
https://zhuanlan.zhihu.com/p/506052424?utm_id=0


## 李沐 动手学深度学习 
- 分布式学习

## CS583: Deep Learning
https://github.com/wangshusen/DeepLearning
### Parallel Computing
- 并行梯度下降：数据分布在不同处理器上，分别计算梯度
- 通信方式
    - 共享内存(share memory): 没有办法做到大规模并行
    - 消息传递(message passing)：节点之间通信
- 架构
    - client-server：worker node上存储数据、做计算
    - peer-to-peer：没有server，所有的节点都做计算，每个节点都有几个邻居，邻居之间可以通信 
#### MapReduce
《MapReduce: Simplified Data Processing on Large Clusters》
架构：client-server
通信：message passing
并行：同步（所有的worker完成工作才能进行下一轮）
google的MapReduce不开源，因此有很多开源实现(Hadoop,Spark)
适合做大数据处理，但是来做机器学习不高效 
broadcast：server可以把信息广播到所有的worker节点上
map：所有的worker并行做的操作
reduce：worker把计算结果传回给server，server把结果整合起来 
数据并行
- 时间开销
    - computation
    - Communication
        - Communication complexity：how many words are transmitted between server and workers
        - Latency(网络延迟)：
        - Communication time： Communication complexity/bandwith + Latency
    - 同步
        - 所有的worker都必须等最慢的worker
#### Parameter Server
- 当前主流
- 异步
    - 比同步快很多
    - 不同worker之间效率要差不多，不然收敛会有问题 
    - 《hogwild a lock-free approach to parallelizing stochastic gradient descent》
- client-server
- message passing
- 框架：Ray
    - https://github.com/ray-project/ray
- 数据并行
##### 李沐讲 parameter server
https://www.bilibili.com/video/BV1YA4y197G8/?spm_id_from=333.999.0.0
- 领域规模大小：编程语言>>AI>>系统>>AI与系统交叉
- （工业界）大规模数据（TB->PB）、分布式机器学习
- 挑战
    - 参数太多，网络开销太大
    - 机器学习都是顺序模型（一个批量算完再算下一个），大量的全局同步会影响性能
    - 容灾很重要：大规模任务失败概率很高（硬件、软件问题）
- 开源实现，适配各种机器学习算法
- 五个关键性特征
    - 通讯效率高：异步通讯，对算法进行压缩，降低通讯量
    - 灵活的一致性模型：各节点访问参数是否完全一致，牺牲一些算法精度
    - 弹性的可扩展性：训练的时候新的节点可以加进来，不会让整个任务停掉
    - 容灾：机器出问题时，多久可以恢复过来
    - 易用
- 实现
    - 服务节点：维护参数
        - 实时复制
    - 计算节点：请求服务节点参数，进行计算
        - 参数：稀疏向量、矩阵
##### 
《scaling distributed machine learning with the parameter server》
《Parameter Server for Distributed Machine Learning》
https://zhuanlan.zhihu.com/p/29968773
    - 专栏：分布式机器学习系统
https://www.zhihu.com/question/26998075
https://www.zhihu.com/question/53851014
参数服务器就类似于MapReduce，是大规模机器学习在不断使用过程中，抽象出来的框架之一。重点支持的就是参数的分布式，毕竟巨大的模型其实就是巨大的参数。
- 参数服务器是个编程框架，用于方便分布式并行程序的编写，其中重点是对大规模参数的分布式存储和协同的支持。
- 工业界需要训练大型的机器学习模型，一些广泛使用的特定的模型在规模上的两个特点：
1. 参数很大，超过单个机器的容纳能力（比如大型Logistic Regression和神经网络）
2. 训练数据巨大，需要分布式并行提速（大数据）

#### Decentralized network
- peer-to-peer：没有server，所有节点都是worker
- message passing
- 数据并行
- 同步 or 异步
- 目前不太流行

#### 使用tensorflow进行分布式计算
- 六个并行计算框架
    - MirroredStrategy：适合一台机器上有多个GPU
        - 同步随机梯度下降
        - 原理：类似MapReduce
            - Ring All-Reduce
    - TPUStrategy
    - MultiWorkerMirroredStrategy
    - CentralStorageStrategy
    - ParameterServerStrategy
    - OneDeviceStrategy
- code
    - learn/MachineLearning/tf_distribute.py
- 《Hands on ml2》Chapter 19
- 业界实践
https://zhuanlan.zhihu.com/p/430383324
- 默认使用全部CPU
https://stackoverflow.com/questions/42845261/does-tensorflow-job-use-multiple-cores-by-default
https://stackoverflow.com/questions/38836269/does-tensorflow-view-all-cpus-of-one-machine-as-one-device
- 模型并行
    - 比较难
    - https://www.tensorflow.org/tutorials/distribute/keras?hl=zh-cn
    - https://medium.com/analytics-vidhya/speeding-up-inference-using-parallel-model-runs-d76dcf393567   
- 分布式训练
https://zhuanlan.zhihu.com/p/469541810
https://zhuanlan.zhihu.com/p/56991108
https://www.tensorflow.org/guide/distributed_training?hl=zh-cn
https://github.com/yahoo/TensorFlowOnSpark
https://towardsdatascience.com/distribute-your-pytorch-model-in-less-than-20-lines-of-code-61a786e6e7b0
https://blog.csdn.net/weixin_39589455/article/details/120759372



#### 联邦学习
- https://www.zhihu.com/question/315844487/answer/920036089
- 《A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection》

## Pathways
- 李沐读paper


## ZeRo
https://zhuanlan.zhihu.com/p/394064174?utm_id=0


## MPI
https://zhuanlan.zhihu.com/p/355652501
https://mpitutorial.com/tutorials/mpi-introduction/zh_cn/
https://www.aminer.cn/research_report/5d00a91800eea1f1d521d890
https://www.youtube.com/watch?v=36nCgG40DJo&ab_channel=SharcnetHPC

## 
- 《Accurate, large minibatch sgd: Training imagenet in 1 hour》
    - https://www.zhihu.com/question/60874090/answer/181413785
    - https://blog.csdn.net/Jing_xian/article/details/79982209
- 《Imagenet training in minutes》
- https://zhuanlan.zhihu.com/p/29032307

## ICML'22大模型技术Tutorial
https://zhuanlan.zhihu.com/p/562741952?utm_campaign=shareopn&utm_medium=social&utm_oi=30949685329920&utm_psn=1556101177766563840&utm_source=wechat_session&s_r=0
https://github.com/alpa-projects/alpa

## Horovod
https://zhuanlan.zhihu.com/p/40578792

## DeepSpeed
https://blog.csdn.net/u010751000/article/details/123516433
https://github.com/microsoft/DeepSpeed
https://zhuanlan.zhihu.com/p/414773915

## Jax
https://zhuanlan.zhihu.com/p/468223891
https://www.zhihu.com/question/306496943
https://zhuanlan.zhihu.com/p/536377657


## 其它参考资料
- https://www.zhihu.com/question/24070061/answer/1325421472
- 《高级能计算并行编程技术--MPI并行程序设计》
- https://zhuanlan.zhihu.com/p/450689346
- https://zhuanlan.zhihu.com/p/466002243
- http://www.cnblogs.com/LeftNotEasy/archive/2010/11/27/1889598.html
- paper
    - FlumeJava : Easy,Efficient Data-Parallel Pipelines
    - Large-scale Incremental Processing Using Distributed Transactions and Notifications
    - SPark: CLuster Computing with Working Sets
    - Pregel:A System for Large-Scale Graph Processing