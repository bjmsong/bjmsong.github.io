---
layout:     post
title:      微软-AI-System
subtitle:   
date:       2022-12-15
author:     bjmsong
header-img: 
catalog: true
tags:
    - ML System
---
## 学习资料
- https://github.com/microsoft/AI-System
- ppt
    - https://github.com/microsoft/AI-System/tree/main/Lectures
- 中文教材  
    - https://github.com/microsoft/AI-System/tree/main/Textbook
    - 更详细
- lab
    - https://github.com/microsoft/AI-System/tree/main/Labs


## 第1章-人工智能系统概述
- 本书介绍的人工智能系统（Artificial Intelligence System）主要是指深度学习系统（Deep Learning System），但是这些系统设计原则大部分也适合于机器学习系统（Machine Learning System）
- 深度学习算法本身无论从模型设计，训练方式也借鉴了很多传统机器学习算法的经典理论与实践方式，但是深度学习系统本身相比机器学习系统从硬件到软件层有更多新的挑战和演化，数据与问题规模变得更大，应用场景与部署也更加广泛。
- 综合起来深度学习系统会综合考虑和借鉴机器学习系统（Machine Learning System），大数据系统（Big Data System）和高性能计算（High Performance Computing）领域和社区中的经典的系统设计，优化与问题解决方法，并演化出针对深度学习算法特点的新的系统设计。
- 深度学习模型变化趋势
    - 更大的模型
        - 以Transformer为基本结构的代表性预训练神经语言模型（Neural Language Model），例如，BERT，GPT-3 等，在自然语言处理和计算机视觉等场景应用越来越广泛。其不断增加的层数和参数量，对底层系统内存管理，分布式训练算子放置，通信，以及硬件设计提出了很大的挑战。
    - 更灵活的结构和建模能力
        - 图神经网络等网络不断抽象多样且灵活的数据结构（例如：图（Graph），树（Tree）等），应对更为复杂的建模需求。进而衍生了新的算子（例如：图卷积等）与计算框架（例如：图神经网络框架等）。
    - 更稀疏的模型结构与模型融合（Model Ensemble）
        - 以多专家模型（Mixture of Experts， MoE） 和 Pathways 模型结构为代表的融合模型结构让运行时的模型更加动态（Dynamic）和稀疏（Sparse），进而提升模型的训练效率减少训练代价，支持更多的任务。给系统设计中以往的静态分析方式带来了不小的挑战，同时驱动运用即时编译（Just In Time Compiling）和运行期（Runtime）更加高效的调度与优化。
    - 更大规模的搜索空间
        - 用户定义更大规模的超参数与模型结构搜索空间，通过超参数搜索优化（HPO）与神经网络结构搜索（NAS）自动化找到最优的模型结构。自动化机器学习（AutoML）为代表的训练方式，衍生出多作业（Multi-Jobs）执行与编排的优化需求。
    - 更多样的训练方式
        - 强化学习（Reinforcement Learning）为代表的算法有比传统训练方式更为复杂的过程。其衍生出训练，推理，数据处理混合部署与协同优化的系统设计需求。
- PyTorch和 TensorFlow等框架应对自动化机器学习，强化学习等多样执行方式，以及细分的应用场景显得不够灵活，需要用户手工做特定的一些优化，没有好的工具和系统的支撑，这些问题一定程度上会拖慢和阻碍算法工程师研发效率，影响算法本身的发展。
- 开源社区中不断涌现针对特定应用领域而设计的框架和工具
    - Hugging Face: 面向语言预训练模型构建的Model Zoo和库框架
    - FairSeq: 面向自然语言处理中场景的序列到序列模型
    - MMDetection: 针对物体检测
    - NNI: 针对自动化机器学习
- 计算框架的进步
    - 第一代框架
        - Theano，Caffe，DisBelief
        - 为数值计算或特定机器学习问题或算法而设计
    - 第二代框架
        - 声明式编程（Declarative Programming）: TensorFlow
        - 命令式编程（Imperative Programming）: PyTorch
        - 存在问题
            - 控制流，数据预处理等其他语言层的逻辑与深度学习模型计算图的割裂造成不便于统一编译与优化
            - 除深度学习模型之外的库不方便卸载计算和利用 GPU 等专有硬件进而造成低效数据流水线
            - 没有侧重面向方面设计造成作业调试诊断困难，运维负担较大
            - Python 语言本身特点是简单，但是并发支持效率不高，不利于静态优化与错误检测等，对大规模工程化实践不友好
- 深度学习系统的设计目标
    - 提供更加高效的编程语言、框架和工具
    - 提供全面多样的深度学习任务需求的系统支持
    - 探索并解决新挑战下的系统设计、实现和演化的问题
    - 提供在更大规模的企业级环境的部署需求
- 深度学习系统的大致组成
    - 开发体验层
    - 框架层
    - 运行时
    - 资源管理与硬件体系结构
- 

## 第2章-神经网络基础


## 第3章-深度学习框架基础


## 第4章-矩阵运算与计算机体系结构


## 第5章-深度学习框架的编译与优化

## 第6章-分布式训练算法与系统


## 第7章-异构计算集群调度与资源管理系统

## 第8章-深度学习推理系统