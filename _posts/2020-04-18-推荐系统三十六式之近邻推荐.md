---
layout:     post
title:      推荐系统三十六式之
subtitle:   近邻推荐
date:       2020-04-18
author:     bjmsong
header-img: img/Recommendation System/th.jpg
catalog: true
tags:
    - 推荐系统
---

### 协同过滤

- 所谓协同，也就是群体互帮互助，互相支持是集体智慧的体现，协同过滤也是这般简单直接，历久弥新
- 维基百科的定义
collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating). 

The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person. 

- **核心数据：用户物品的关系矩阵**
- 协同过滤是一个比较大的算法范畴。通常划分为两类：
  - **基于记忆(memory-based)**
    - 就是记住每个人消费过什么东西，然后给他推荐相似的东西，或者推荐相似的人消费的东西
    - user-based，item-based
  - **基于模型(model-based)**
    - 从用户物品关系矩阵中去学习一个模型，从而把那些矩阵空白处填满
    - 矩阵分解


#### User-Based

- 先根据历史消费行为帮你找到一群和你口味很相似的用户；然后根据这些和你很相似的用户再消费了什么新的、你没有见过的物品，都可以推荐给你
  
    - 物以群分，人以类聚
    
- step1: 构造用户向量
  
    - 基于用户物品的关系矩阵
    - 向量的维度就是物品的个数
    - 向量是稀疏的
        - 稀疏矩阵：`CSR`,` COO`
    - 向量维度上的取值可以是简单的 0 或者 1
    
- step2: 计算用户之间的相似度
    - **降低计算复杂度**
        - 用户量很大
            - **方法一：拆成`Map Reduce`任务，将原始矩阵 Map 成键为用户对，值为两个用户对同一个物品的评分之积。Reduce阶段对这些乘积再求和。最后再归一化**
            - 方法二：不用基于用户的协同过滤
        - 向量很长
            - 向量采样：`DIMSUM`，Twitter提出，Spark已实现
            - 向量化计算：`numpy`
        - 如果数据量不大，一般来说不超过百万个，然后矩阵又是稀疏的，那么很多单机版本工具其实更快：`KGraph`、`GraphCHI`
    
- step3: 推荐相似用户喜欢的物品
  
    <ul> 
    <li markdown="1">
    ![]({{site.baseurl}}/img/Recommendation System/36/user-based.png) 
    </li> 
    </ul> 
    
    - 只有相似用户喜欢过的物品需要计算，这个大大的赞，这个数量相比全部物品少了很多
    - 把计算过程拆成 Map Reduce 任务
      - **一般来说，中小型公司如果没有特别必要的话，不要用分布式计算，看上去高大上、和大数据沾上边了，实际上得不偿失**
      - **拆分 Map Reduce 任务也不一定非要用 Hadoop 或者 Spark 实现。也可以用单机实现这个过程**
      - 因为一个 Map 过程，其实就是将原来耦合的计算过程解耦合了、拍扁了，这样的话我们可以利用多线程技术实现 Map 效果。例如 C++ 里面 `OpenMP` 库可以让我们无痛使用多线程，充分剥削计算机所有的核
    
- 算法改进
    - 惩罚对热门物品的喜欢程度：这是因为，热门的东西很难反应出用户的真实兴趣，更可能是被煽动，或者无聊随便点击的情形，这是群体行为常见特点
    - 增加喜欢程度的时间衰减，一般使用一个指数函数，指数就是一个负数，值和喜欢行为发生时间间隔正相关即可，这很好理解，小时候喜欢的东西不代表我现在的口味，人都是会变的，这是人性
    - 将user-user-item 变为 user-expert-item

- 产出
    - 相似用户列表
    - 基于用户的推荐结果
    
- 缺点
    - 用户数量大的时候，计算吃力
    - 用户口味变化很快
    - 数据稀疏，用户和用户之间共同的消费行为实际上是比较少的，而且一般是热门物品，对发现用户兴趣帮助不大。



#### Item-Based

- 《Item-Based Collaborative Filtering Recommendation Algorithms》
- user-based协同过滤的缺点
    - 用户数量往往比较大，计算起来非常吃力，成为瓶颈
    - 用户的口味其实变化还是很快的，不是静态的，所以兴趣迁移问题很难反应出来
    - 数据稀疏，用户和用户之间有共同的消费行为实际上是比较少的，而且一般都是一些热门物品，对发现用户兴趣帮助也不大
- **item-based协同过滤的优点**
    - 可推荐的物品数量一般少于用户数量
    - 物品之间的相似度比较静态，它们变化的速度没有用户的口味变化快；所以完全解耦了用户兴趣迁移这个问题
    - 物品对应的消费者数量较大，计算物品之间的相似度稀疏度较好
- 步骤
    - 构建用户物品的关系矩阵，矩阵元素可以是用户的消费行为，也可以是消费后的评价，还可以是对消费行为的某种量化如时间、次数、费用等
    - 计算物品之间的相似度
        - 余弦相似度
        - **改进：去除bias**
            - 物品中心化：把矩阵中的分数，减去的是物品分数的均值；先计算每一个物品收到评分的均值，然后再把物品向量中的分数减去对应物品的均值。这样做的目的是什么呢？去掉物品中铁杆粉丝群体的非理性因素，例如一个流量明星的电影，其脑残粉可能会集体去打高分，那么用物品的均值来中心化就有一定的抑制作用
            - 用户中心化：把矩阵中的分数，减去对应用户分数的均值；先计算每一个用户的评分均值，然后把他打过的所有分数都减去这个均值
    - 计算推荐结果
        - 应用场景
            - TopK
            - 相关推荐
    - 优化
        - item聚类，形成topic，将user-item-item 变为 user-topic-item
- **Slope one 算法**
    - 经典的item-based方法存在的问题
        - 相似度矩阵无法实时更新
        - 没有考虑相似度的置信问题：例如，两个物品，他们都被同一个用户喜欢了，且只被这一个用户喜欢了，那么余弦相似度计算的结果是 1，这个 1 在最后汇总计算推荐分数时，对结果的影响却最大
    - Slope one算法针对这些问题有很好的改进
    - 针对评分矩阵，不适用与行为矩阵



### 相似度计算方法

- **推荐算法中的相似度门派，实际上有这么一个潜在假设：如果两个物体很相似，也就是距离很近，那么这两个物体就很容易产生一样的动作**
- **余弦相似度适用于评分数据，杰卡德相似度适合用于隐式反馈数据**

- **欧式距离**

    <ul> 
    <li markdown="1">
    ![]({{site.baseurl}}/img/Recommendation System/36/欧式距离.png) 
    </li> 
    </ul> 

    <ul> 
    <li markdown="1">
    把范围为 0 到正无穷的欧式距离转换为 0 到 1 的相似度
    ![]({{site.baseurl}}/img/Recommendation System/36/欧式距离转化.png) 
    </li> 
    </ul> 

- **余弦相似度**
    
    <ul> 
    <li markdown="1">
    ![]({{site.baseurl}}/img/Recommendation System/36/余弦相似度.png) 
    </li> 
    </ul> 
    
    - 需要对向量长度做归一化
    - 存在问题：对绝对值大小不敏感
        - 比如：用户 A 对两部电影评分分别是 1 分和 2 分，用户 B 对同样这两部电影评分是 4 分和 5 分。用余弦相似度计算出来，两个用户的相似度达到 0.98。这和实际直觉不符，用户 A 明显不喜欢这两部电影
        - 可以使用调整的余弦相似度（Adjusted Cosine Similarity）方法：调整的方法很简单，就是先计算向量每个维度上的均值，然后每个向量在各个维度上都减去均值后，再计算余弦相似度。
            - 前面这个小例子，用调整的余弦相似度计算得到的相似度是 -0.1，呈现出两个用户口味相反，和直觉相符。
    
- **皮尔逊相关度**

    - 实际上也是一种余弦相似度，不过先对向量做了中心化，向量 p 和 q 各自减去向量的均值后，再计算余弦相似度

    <ul> 
    <li markdown="1">
    ![]({{site.baseurl}}/img/Recommendation System/36/皮尔逊相关度.png) 
    </li> 
    </ul> 

    - 皮尔逊相关度计算结果范围在 -1 到 1。-1 表示负相关，1 比表示正相关
    - 由于皮尔逊相关度度量的时两个变量的变化趋势是否一致，所以不适合用作计算布尔值向量之间相关度，因为两个布尔向量也就是对应两个 0-1 分布的随机变量，这样的随机变量变化只有有限的两个取值，根本没有“变化趋势，高低起伏”这一说。

- **Jaccard相似度**
    
    - 两个集合的交集元素个数在并集中所占的比例
    - **适用于布尔向量**
    - 适用于隐式反馈数据
    - 对应的计算方式是：
        - 分子是两个布尔向量做点积计算，得到的就是交集元素个数；
        - 分母是两个布尔向量做或运算，再求元素和。


### 参考资料
- Amazon.com recommendations: item-to-item collaborative filtering
- Slope One Predictors for Online Rating-Based Collaborative Filtering
- Item-Based Collaborative Filtering Recommendation Algorithms
    - GroupLens 的研究团队对比了不同的 Item-to-Item 的推荐算法。
- Collaborative Recommendations Using Item-to-Item Similarity Mappings
- Recommender Systems Handbook（第 4 章）
- Item2Vec: Neural Item Embedding for Collaborative Filtering
    - 这篇就是借鉴了 word2vec 在语言建模中的思路，为推荐系统的行为建模，从中为物品学习嵌入向量
- 推荐系统实战