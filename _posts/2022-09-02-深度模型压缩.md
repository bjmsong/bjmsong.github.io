---
layout:     post
title:      深度模型压缩与加速
subtitle:   
date:       2022-09-02
author:     bjmsong
header-img: 
catalog: true
tags:
    - 模型优化与部署
---
《Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding》
https://github.com/cedrickchee/awesome-ml-model-compression
https://github.com/j-marple-dev/model_compression
https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone
https://github.com/memoiry/Awesome-model-compression-and-acceleration
https://github.com/chester256/Model-Compression-Papers

## Architecture Design
- 矩阵分解
    - ALBERT
- 权值共享
- 分组卷积
- 分解卷积,小型CNN
https://blog.csdn.net/briblue/article/details/84995553
https://zhuanlan.zhihu.com/p/49465950
- 全局平均池化代替全连接层

## Network Pruning 模型剪枝
- prune redundant weights or neurons
- importance of weight: L1,L2
- importance of neuron: the number of times it wasn't zero on a given dataset
- 将权重矩阵中不重要的参数设置为0，结合稀疏矩阵来进行存储和计算
- 为了保证performance，需要一小步一小步地进行迭代剪枝
- 一般是prune neuron：神经元直接拿掉
- prune weight存在的问题
    - 连接直接拿掉，不容易实现
    - weight设为0，容易实现，方便加速，但是模型没有真正压缩，并没有得到加速

## Knowledge Distillation 蒸馏
- student模型学习teacher模型的输出
- 没太有用？

## Parameter Quantization 量化
《Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference》
- 伪量化
    - 利用低精度来保存每一个网络参数，同时保存拉伸比例scale和零值对应的浮点数zero_point
    - 存储时使用了低精度进行量化，但推理时会还原为正常高精度
    - 伪量化可以实现模型压缩，但对模型加速没有多大效果
- 聚类与伪量化
    - 进阶：霍夫曼编码
        - Represent frequent clusters by less bits, represent rare clusters by more bits
- 定点化
    - 与伪量化不同的是，定点化在推理时，不需要还原为浮点数
    - 《Deep learning with limited numerical precision》
- 二值化
《Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1》
https://blog.csdn.net/elaine_bao/article/details/50950969
- 参考资料
    - 消费级GPU运行1760亿参数大模型
    https://mp.weixin.qq.com/s/gyLzQhW0mZxKXtCUau3ScQ
    https://github.com/timdettmers/bitsandbytes
    - https://blog.csdn.net/WZZ18191171661/article/details/103332338/
    - https://jilei-hou.github.io/2022/06/18/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/
    - 社区分享 | TensorFlow 模型优化：模型量化
    https://mp.weixin.qq.com/s/9QeVVESP3_rBZ6n_D96lwg
    - https://zhuanlan.zhihu.com/p/505570612
    - https://www.zhihu.com/question/421743958
    
## Dynamic Computation
- adjust the computation power it need
- possible solution
    - Train multiple classifiers
    - Classifiers at the intermedia layer

## TensorFlow Lite
https://blog.csdn.net/weixin_38346042/article/details/124587414?spm=1001.2014.3001.5501
https://www.tensorflow.org/lite?hl=zh-cn
https://blog.csdn.net/liuhongshuo2012/article/details/106573682/

## TensorFlow 模型优化工具包
https://www.tensorflow.org/model_optimization?hl=zh-cn
https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&album_id=1642498502104547335&__biz=MzU1OTMyNDcxMQ==#wechat_redirect
- 量化
- 剪枝

## 阿里妈妈搜索广告CTR模型的“瘦身”之路
https://mp.weixin.qq.com/s/fOA_u3TYeSwAeI6C9QW8Yw

## 参考资料
- 李宏毅：模型压缩系列讲解
https://www.bilibili.com/video/BV1LE411Z76J?spm_id_from=333.337.search-card.all.click&vd_source=7798c62f92ce545f56fd00d4daf55e26
http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20
    - 第七课
- 《Stripes: Bit-serial deep neural network computing》
- 《Minerva: Enabling low- power, highly-accurate deep neural network accelerators》
- https://www.bilibili.com/video/BV1364y1d7Ks?is_story_h5=false&p=1&share_from=ugc&share_medium=android&share_plat=android&share_session_id=59556101-a815-4452-bc93-b8e4ee3797b3&share_source=WEIXIN&share_tag=s_i&timestamp=1661949215&unique_k=iw6RbGx
- http://eyeriss.mit.edu/2019_neurips_tutorial.pdf?ich_args2=526-06113205060278_e0b61138dc2d908aa0766d50302e6d8a_10001002_9c896324d5cbf0d49239518939a83798_92e0a859ed6aa28355c3deea32562911
- https://zhuanlan.zhihu.com/p/421154873
- https://zhuanlan.zhihu.com/p/138059904
- https://www.zhihu.com/question/329372124/answer/2675692342


