---
layout:     post
title:      深度模型量化
subtitle:   
date:       2022-12-13
author:     bjmsong
header-img: img/ai.jpg
catalog: true
tags:
    - 模型压缩
---

## 什么是模型量化

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/1.png) 
</li> 
</ul> 



## 模型量化的优点

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/2.png) 
</li> 
</ul> 



## 量化技术落地的三大挑战
<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/3.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/4.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/5.png) 
</li> 
</ul> 



## 量化原理

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/6.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/7.png) 
</li> 
</ul> 

浮点与定点数据的转化公式如下：

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/8.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/9.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/10.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/11.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/12.png) 
</li> 
</ul> 



### 矩阵运算的量化

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/13.png) 
</li> 
</ul> 



### Per-channel vs per-layer

Per-channel量化是将每个通道或特征图的权重参数独立量化，即对于每个通道/特征图，使用一个单独的量化参数集合。这种方法可以更好地适应每个通道/特征图的统计特性，并提高模型的表现和压缩效率。

Per-layer量化是将整个层的权重参数统一量化，即对于每个层，使用一个单独的量化参数集合。这种方法比Per-channel量化更简单，但可能会在某些情况下丢失模型性能和精度。



## 量化部署

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/14.png) 
</li> 
</ul> 

假设模型已经量化好，即模型算子已经转换为`int`类型（如下图的`Conv2D`）。在模型推理阶段，需要在计算图中插入`Quantize`，`Dequantize`，`Requantize`3种算子。

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/15.png) 
</li> 
</ul> 

3种算子的计算过程如下，其中的`scale`，`offset`是在推理前已经计算好的。

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/16.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/17.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/18.png) 
</li> 
</ul> 



## 动态训练后量化(Post-Training Quantization Dynamic, PTQ Dynamic)

不需要重新进行训练或者是标签数据，仅将模型中特定算子的权重从FP32类型映射成INT8/16类型。因此这是一种轻量化的量化方法。在大多数情况下PTQ Dynamic使用8bit量化时可以接近浮点模型的精度。

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/19.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/20.png) 
</li> 
</ul> 




## 量化感知训练(Quantization Aware Training, QAT)

让模型感知量化运算对模型精度带来的影响，通过finetune训练降低量化误差。

QAT算法流程：

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/21.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/22.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/23.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/24.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/25.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/26.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/27.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/28.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/29.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/30.png) 
</li> 
</ul> 




## 静态训练后量化(Post-Training Quantization Static, PTQ Static)

使用少量无标签较准数据，采用KL散度等方法计算量化比例因子。

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/31.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/32.png) 
</li> 
</ul> 

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/33.png) 
</li> 
</ul> 



## 量化方法比较

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/compress/quantization/34.png) 
</li> 
</ul> 

