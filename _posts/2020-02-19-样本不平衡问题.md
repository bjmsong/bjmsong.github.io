---

layout:     post
title:      样本不平衡问题
subtitle:   
date:       2020-02-19
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---



## 模型效果评估指标

- Lift

  - 它衡量的是，与不利用模型相比，模型的预测能力 “变好” 了多少。实质上它强调的是投入与产出比
  - 也就是跟随机准确率比较（c+d/a+b+c+d）



### 分类问题

- Confusion Matrix （混淆矩阵）

  <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/confusion matrix.png) 
  </li> 
  </ul> 

  $$
Precision =true positive/ total predicted positive
  $$

  $$
Recall = true positive/total actual positive
  $$

  $$
F1 = 2*(Precision*Recall)/(Precision+Recall)
  $$

- ROC

  <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/roc.jpg) 
  </li> 
  </ul> 

  - ROC曲线（The Receiver Operating Characteristic Curve）给出的是不同分类阈值情况下真正率（TPr）和假正率（FPr）的变化曲线

  - 为了使得ROC曲线之间能更好的进行比较，通常采用AUC，AUC的值越大，表明分类性能越好

    - AUC这个指标有两种解释方法

      1. ROC曲线下的面积

      2. 关于排序能力，例如0.7的AUC，其含义可以大概理解为：**给定一个正样本和一个负样本，在70%的情况下，模型对正样本的打分高于对负样本的打分**

    - 相比于准确率、召回率、F1等指标，AUC有一个独特的优势，就是不关注具体得分，只关注排序结果，这使得它特别适用于排序问题的效果评估，例如推荐排序的评估。

  - 有文献指出，ROC曲线相比PR曲线有一个非常好的特性：就是当正负样本分布发生变化的时候，ROC曲线的形状能够基本保持不变，而PR曲线的形状会发生较剧烈的变化 

- PR

  - PR曲线（Precision-Recall Curve）给出的是不同分类阈值情况下查准率（Precision）和查全率（Recall）的变化曲线
  - **PRC曲线在正负样本比例悬殊较大时更能反映分类的真实性能**
    - 原因是FPR 和 TPR (Recall) 只与真实的正例或负例中的一个相关（可以从他们的计算公式中看到），而Precision则同时与真实的正例与负例都有关

- KS

  - KS（Kolmogorov-Smirnov Curve）曲线横轴为不同的分类阈值，纵轴为真正率（TPr）和假正率（FPr）的变化曲线
  - KS值常在**征信评分模型**中用于衡量区分预测正负样本的分隔程度，KS值越大，表明正负样本区分的程度越好
  - 但并非所有的情况KS值都是越高越好的，尤其在征信模型中，如正负样本完全分错的情况下，KS值依旧可以很高。征信模型最期望得到的信用分数分布为正态分布，如果KS值过大，如0.9，就可以认为正负样本分得过开了，不太可能是正态分布，反而比较可能是极端化的分布状态（如U字型），这样的分数就很不好，基本可以认为不可用。

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/ROC PR KS.png) 
</li> 
</ul> 

- Cumulative gains chart
  - 横坐标表示：代表我们样本的百分比，假设有10000个样本，0.1代表1000个，1代表10000个样本
  - 纵坐标表示：代表横轴所代表的那么多样本中，判断正确的比率
  - 曲线含义：采用模型进行预测。y值的分子代表模型预测且预测为正例的人数，分母是整个群体正例人数。
- Silhouette Analysis



### 回归问题

- MAE : Mean Absolute Error，平均绝对误差 
- RMSE：Root Mean Square Error，方均根差
  - 对异常点较敏感
  - **改进：使用误差的分位数来代替，如中位数来代替平均数。假设100个数，最大的数再怎么改变，中位数也不会变，因此其对异常点具有鲁棒性**
- MAPE：Mean Absolute Percentage Error， MAPE不仅仅考虑预测值与真实值的误差，还考虑了误差与真实值之间的比例，在某些场景下，比如房价从0.5w到5w之间，0.5预测成1.0与5.0预测成4.5的差距是非常大的



### Learning Curve

- 学习曲线就是通过画出不同训练集大小时训练集和交叉验证的准确率，可以看到模型在新数据上的表现，进而来判断模型是否方差偏高或偏差过高，以及增大训练集是否可以减小过拟合。

  - **Bias：用所有可能的训练数据集训练出的所有模型的输出的平均值与真实模型的输出值之间的差异**
  - **Variance：不同的训练数据集训练出的模型输出值之间的差异**

- 好像有点鸡肋：不画learning curve，通过比较训练集、验证集和理想的误差，就已经可以判断出是高偏差还是高方差了

- <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/learning  curve.png) 
  </li> 
  </ul> 





## 解决方法

- 过采样/欠采样：smote

- 使用F1，而不是AUC
  
- 自定义loss function

- 自定义评价函数

  ```
  xgb.train(params, dtrain, num_rounds, watchlist, feval=misclassified, maximize=False)
  
  def misclassified(pred_probs, dtrain):
  
  	labels = dtrain.get_label() # obtain true labels
  
  	preds = pred_probs > 0.5 # obtain predicted values
  
  	return 'misclassified', np.sum(labels != preds)
  ```

- 调参，如xgboost

  - min_child_weight 设的小一点
  
  - scale_pos_weight = 0值的样本数量/1值的样本数量
  
  - max_delta_step
  
- 设置weight：如spark初始化DMatrix

  

## 参考资料

- [腾讯技术工程-机器学习模型可解释性的详尽介绍](https://www.jiqizhixin.com/articles/2019-10-30-9)
- https://blog.csdn.net/pipisorry/article/details/51788927
- [ROC vs PR曲线](https://www.cnblogs.com/JesusAlone/p/9762352.html)

