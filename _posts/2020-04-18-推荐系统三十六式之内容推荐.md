---
layout:     post
title:      推荐系统三十六式之
subtitle:   内容推荐
date:       2020-04-18
author:     bjmsong
header-img: img/Recommendation System/th.jpg
catalog: true
tags:
    - 推荐系统
---


### 用户画像(User Profile)

- 给机器看，而不是给人看的
- 用户和物品**向量化**
- 用户&产品指标来源
    - 基本信息
    - 统计历史数据
    - 通过模型学习
- [参考阅读](https://bjmsong.github.io/2020/03/07/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/)



### 从文本中提取用户画像

#### 结构化文本

1. 关键词提取
    - TF-IDF
    - TextRank：思想类似pageRank
    
2. 实体识别：人物、位置和地点、著作、影视剧、历史事件和热点事件等
    - 常用方法：基于词典的方法结合CRF模型,bi-LSTM+CRF，隐马尔科夫模型(HMM)
        - 字典法：提前准备好各种实体的词典，使用trie-tree数据结构存储，拿着分好的词去词典里找
    - 命名实体识别(NER)常被认为是序列标注问题，和分词、词性标注属于同一类问题
        - 序列标注问题：就是给你一个字符序列，从左往右遍历每个字符，一边遍历一边对每一个字符分类，分类的体系因序列标注问题不同而不同： 
            - 分词问题：对每一个字符分类为“词开始”“词中间”“词结束”三类之一；
            - 词性标注：对每一个分好的词，分类为定义的词性集合之一；
            - 实体识别：对每一个分好的词，识别为定义的命名实体集合之一
    - 工具：spaCy
    
3. 内容分类：用分类来表达较粗粒度的结构化信息
    - 短文本分类：SVM
    - 工具：FastText，性能比肩深度学习，速度更快
    
4. 主题模型：从大量已有文本中学习主题向量，然后再预测新的文本在各个主题上的概率分布情况

    - LDA：工程上较难的是并行化
      - 工具：Gensim、PLDA
    - 短文本：BTM

5. 词嵌入（Word Embedding）

    - 为每一个词学习得到一个稠密的向量
    - 挖掘出字面意思之下的语义信息，并用有限的维度表达出来

    - Word2Vec：最大的贡献在于一些工程技巧上的优化，使得百万词的规模在单机上可以几分钟轻松跑出来



#### 标签选择

- 根据用户行为数据把物品的结构化结果传递给用户，与用户自己的结构化信息合并

    - 为用户挑选有信息量的结构化数据，作为其画像内容

- **用户在产品上看到了很多我们用各种逻辑和理由展示给他的物品，他只从中消费了一部分物品。现在问题就是，到底是那些特性吸引了他消费呢？**

- 简单粗暴的办法：直接把用户产生过行为的物品标签累积在一起

- **另一种思路：把用户对物品的行为，消费或者没有消费看成是一个分类问题。用户用实际行动帮我们标注了若干数据，那么挑选出他实际感兴趣的特性就变成了特征选择问题**
  
    - 卡方检验(CHI)
      
        - 检验“词和某个类别C相互独立”这个假设是否成立，和这个假设偏离越大，就越说明这个词和类别 C 暗中有一腿，那当然这个词就是关键词了
        
        <ul> 
        <li markdown="1">
        ![]({{site.baseurl}}/img/Recommendation System/36/卡方检验.png) 
        </li> 
        </ul> 
        
        <ul> 
        <li markdown="1">
        ![]({{site.baseurl}}/img/Recommendation System/36/卡方检验2.png) 
        </li> 
        </ul> 
        
    - 信息增益(IG)   ：决策树算法
    
    - 基本思想
        1. 把物品的结构化内容看成文档； 
        2. 把用户对物品的行为看成是类别；
        3. 每个用户看见过的物品就是一个文本集合；
        4. 在这个文本集合上使用特征选择算法选出每个用户关心的东西。
    
- 这些方法都是在离线阶段批量完成的，把用户的画像生成配置成离线任务，每天更新一遍，次日就可以使用新的用户画像



### 基于内容的推荐系统

- **所谓的基于内容推荐，通俗一点来讲，就是一个包装成推荐系统的信息检索系统**
- **重要性**
    - 内容数据（比如文本）容易获得，并且蕴含丰富的信息
    - 很多时候没有用户行为数据
        - 新用户
        - 新物品

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/Recommendation System/36/基于内容的推荐.png) 
</li> 
</ul> 

- 内容这一端：内容源经过内容分析，得到结构化的内容库和内容模型，也就是物品画像。用户这一端：用户看过推荐列表后，会产生用户行为数据，结合物品画像，经过用户分析得到用户画像
  - 以后对于那些没有给用户推荐过的新内容，经过相同的内容分析过程后就可以经过推荐算法匹配，计算得到新的推荐列表给用户。如此周而复始，永不停息

- **内容源**
    - 爬虫：非常复杂、非常有学问，比推荐算法难多了
      - 在互联网中，抓数据是一件可做不可说的事情，哪怕是市值几千亿的大厂，也有专门的小分队抓数据，补充推荐系统每天的内容消耗。因为，只有当内容有多样性了，一个推荐系统才有存在的合法性，所以大厂职工们抓数据也是为了保住自己的饭碗
    - 数据清洗：去重与识别垃圾内容、色情内容、政治敏感内容
- **内容分析和用户分析**
    - 基于内容的推荐，最重要的不是推荐算法，而是内容挖掘和分析
    - 内容挖掘越深入，哪怕早期推荐算法仅仅是非常硬的规则，也能取得不俗的效果
    - 分析越深入，能抓住的用户群体就越细致，推荐的转化率就越高
    - 产出
      - 结构化内容库：最重要的用途是结合用户反馈行为去学习用户画像
      - 内容分析模型：当新的物品刚刚进入时，需要实时地被推荐出去，这时候对内容的实时分析，提取结构化内容，再与用户画像匹配
- **内容推荐算法**
    - 最简单的方法：计算用户画像和内容端的相似性
        - 用户的画像内容就表示为稀疏的向量，同时内容端也有对应的稀疏向量，两者之间计算余弦相似度，根据相似度对推荐物品排序
        - 可解释性强
        - 可以考虑不同字段的重要性不同
    - 信息检索中的相关性计算方法：BM25F
        - Elastic Search
    - 机器学习方法
        - 收集某种行为（如点击、收藏、转发等）的日志数据，转换为训练样本，训练预估模型。
        - 更科学，可迭代

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/Recommendation System/36/内容推荐.jpg) 
</li> 
</ul> 



### 参考资料
- Bag of Tricks for Efficient Text Classification
    - fastText背后原理：可以训练词嵌入向量，文本多分类，效率和线性模型一样，效果和深度学习一样，值得拥有
- The Learning Behind Gmail Priority Inbox
    - 基于文本和行为给用户建模的思路，是信息流推荐的早期探索，Gmail 智能邮箱背后的原理
- Recommender Systems Handbook(第三章，第九章)
- 文本上的算法: 深入浅出自然语言处理
    - 介绍了文本挖掘中常用的算法，及基础概念。内容涉及概率论，信息论，文本分类，聚类，深度学习，推荐系统等
- LDA 数学八卦
    - 由浅入深地讲解 LDA 原理，对于实际 LDA 工具的使用有非常大的帮助