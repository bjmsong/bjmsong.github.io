---

layout:     post
title:      模型评估
subtitle:   
date:       2020-02-19
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---



### 模型效果评价指标

- Lift

  - 也就是跟随机准确率比较
  
  - 它衡量的是，与不利用模型相比，模型的预测能力 “变好” 了多少。实质上它强调的是投入与产出比
  
    

### （监督）分类问题

#### 二分类问题
- Confusion Matrix （混淆矩阵）

  <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/eval/confusion matrix.png) 
  </li> 
  </ul> 

  $$
Precision =true positive/ total predicted positive
  $$

  $$
Recall = true positive/total actual positive
  $$

  $$
F1 = 2*(Precision*Recall)/(Precision+Recall)
  $$

- ROC

  <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/eval/roc.jpg) 
  </li> 
  </ul> 

  - ROC曲线（The Receiver Operating Characteristic Curve）给出的是不同分类阈值情况下真正率（TPr，即recall）和假正率（FPr）的变化曲线

  - 为了使得ROC曲线之间能更好的进行比较，通常采用AUC，AUC的值越大，表明分类性能越好

    - AUC这个指标有两种解释方法

      1. ROC曲线下的面积

      2. 关于排序能力，例如0.7的AUC，其含义可以大概理解为：**给定一个正样本和一个负样本，在70%的情况下，模型对正样本的打分高于对负样本的打分**

    - 相比于准确率、召回率、F1等指标，AUC有一个独特的优势，就是不关注具体得分，只关注排序结果，这使得它特别适用于排序问题的效果评估，例如推荐排序的评估。

- PR

  - PR曲线（Precision-Recall Curve）给出的是不同分类阈值情况下查准率（Precision）和查全率（Recall）的变化曲线
  
- KS

  - KS（Kolmogorov-Smirnov Curve）曲线横轴为不同的分类阈值，纵轴为真正率（TPr）和假正率（FPr）的变化曲线
  - KS值常在**征信评分模型**中用于衡量区分预测正负样本的分隔程度，KS值越大，表明正负样本区分的程度越好
  - 但并非所有的情况KS值都是越高越好的，尤其在征信模型中，如正负样本完全分错的情况下，KS值依旧可以很高。征信模型最期望得到的信用分数分布为正态分布，如果KS值过大，如0.9，就可以认为正负样本分得过开了，不太可能是正态分布，反而比较可能是极端化的分布状态（如U字型），这样的分数就很不好，基本可以认为不可用。

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/eval/ROC PR KS.png) 
</li> 
</ul> 

- Cumulative gains chart
  - 横坐标表示：代表我们样本的百分比，假设有10000个样本，0.1代表1000个，1代表10000个样本
  - 纵坐标表示：代表横轴所代表的那么多样本中，判断正确的比率
  - 曲线含义：采用模型进行预测。y值的分子代表模型预测且预测为正例的人数，分母是整个群体正例人数。
- Silhouette Analysis

#### 多分类问题
- 对于某一个类别
  - True Positive: prediction，label 都属于这个类别
  - True Negative: prediction，label 都不属于这个类别

#### 多标签问题
- 一个样本可以同时属于多个类别 

#### 排序问题
- 应用于推荐、搜索场景，对每个用户生成一个列表，列表里面是模型预测的跟用户最相关的物品
- Precision@k：推荐列表中前k个物品，有多少个在真实列表中
- Mean Average Precision（MAP）：推荐列表中前k个物品，有多少个在真实列表中，考虑位置
- NDCG@k：推荐列表中前k个物品，有多少个在真实列表中，考虑位置，相关性，归一化


### 回归问题

- MAE : Mean Absolute Error，平均绝对误差 
- RMSE：Root Mean Square Error，方均根差
  - 对异常点较敏感
  - **改进：使用误差的分位数来代替，如中位数来代替平均数。假设100个数，最大的数再怎么改变，中位数也不会变，因此其对异常点具有鲁棒性**
- MAPE：Mean Absolute Percentage Error， MAPE不仅仅考虑预测值与真实值的误差，还考虑了误差与真实值之间的比例，在某些场景下，比如房价从0.5w到5w之间，0.5预测成1.0与5.0预测成4.5的差距是非常大的



#### Learning Curve

- 学习曲线就是通过画出不同训练集大小时训练集和交叉验证的准确率，可以看到模型在新数据上的表现，进而来判断模型是否方差偏高或偏差过高，以及增大训练集是否可以减小过拟合。

  - **Bias：用所有可能的训练数据集训练出的所有模型的输出的平均值与真实模型的输出值之间的差异**
  - **Variance：不同的训练数据集训练出的模型输出值之间的差异**

- 好像有点鸡肋：不画learning curve，通过比较训练集、验证集和理想的误差，就已经可以判断出是高偏差还是高方差了

- <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/eval/learning curve.png) 
  </li> 
  </ul> 



### 参考资料

- https://spark.apache.org/docs/2.3.0/mllib-evaluation-metrics.html
- [腾讯技术工程-机器学习模型可解释性的详尽介绍](https://www.jiqizhixin.com/articles/2019-10-30-9)
- https://blog.csdn.net/simple_the_best/article/details/52296608
- https://blog.csdn.net/pipisorry/article/details/51788927
- [ROC vs PR曲线](https://www.cnblogs.com/JesusAlone/p/9762352.html)
- [标准化SMOTE采样框架实现与应用](https://mp.weixin.qq.com/s?__biz=MzU0MDkwNTEwNA==&mid=2247485127&idx=1&sn=5d87863616235fc78183bd975549afaf&chksm=fb335d38cc44d42e5937fc55f32a805c382ccc4dceb81effec5006d9fb068d739b3cfca99884&mpshare=1&scene=1&srcid=0923TBh912QlEwnLSlcXUB5E&sharer_sharetime=1569246580110&sharer_shareid=49581f7bdbef8664715f595bc62d7044&key=40244416acac1968edd7318efc6e9c268f3418b1c7de1cb1559c9198d1b763de6e061a14eb84f7ab57b6b095e16d5ca68d2d2b5f7cdbb58e633807ea25142c3050a5c32a8464f0c365f945f162f0af00&ascene=1&uin=MjM1OTMwMzkwMA%3D%3D&devicetype=Windows+10&version=62060833&lang=en&pass_ticket=TiPHQC4Wh5A6AqrSE4OyCRA0nErRaUvNEBSXijdw%2F1Z5NrrfASMX97gm21JRq%2FJw)

  

