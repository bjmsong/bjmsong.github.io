---

layout:     post
title:      模型评估
subtitle:   
date:       2020-02-19
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---



### 模型效果评价指标

- Lift

  - 也就是跟随机准确率比较
  
  - 它衡量的是，与不利用模型相比，模型的预测能力 “变好” 了多少。实质上它强调的是投入与产出比
  
    

### （监督）分类问题

#### 二分类问题
- Confusion Matrix （混淆矩阵）

  <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/eval/confusion matrix.png) 
  </li> 
  </ul> 

  $$
Precision =true positive/ total predicted positive
  $$

  $$
Recall = true positive/total actual positive
  $$

  $$
F1 = 2*(Precision*Recall)/(Precision+Recall)
  $$

- ROC

  <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/eval/roc.jpg) 
  </li> 
  </ul> 

  - ROC曲线（The Receiver Operating Characteristic Curve）给出的是不同分类阈值情况下真正率（TPr，即recall）和假正率（FPr）的变化曲线

  - 为了使得ROC曲线之间能更好的进行比较，通常采用AUC，AUC的值越大，表明分类性能越好

    - AUC这个指标有两种解释方法

      1. ROC曲线下的面积

      2. 关于排序能力，例如0.7的AUC，其含义可以大概理解为：**给定一个正样本和一个负样本，在70%的情况下，模型对正样本的打分高于对负样本的打分**

    - 相比于准确率、召回率、F1等指标，AUC有一个独特的优势，就是不关注具体得分，只关注排序结果，这使得它特别适用于排序问题的效果评估，例如推荐排序的评估。
  
  - AUC 指标的优点：
    - ROC 曲线具有不随样本比例而改变的良好性质，因此能够在样本比例不平衡的情况下较好地反映出分类器的优劣，AUC 作为 ROC 曲线下面积，也继承了对 ROC 这一优势。
    - AUC 继承了 ROC 曲线评估指标无需手动设定阈值的优良特性，直接从整体上（离线排序）方面衡量算法的表现。
    - AUC计算主要与排序有关，所以他对排序敏感，而对预测分数绝对值没那么敏感，对相对值敏感。
  - AUC指标的不足之处：
    - 只反映了模型的整体性能，看不出在不同点击率区间上的误差情况； 
    - 只反映了排序能力，关注的是概率值的相对大小，与阈值和概率值的绝对大小没有关系，没有反映预测精度；（简单说，如果对一个模型的点击率统一乘以2，AUC不会变化，但显然模型预测的值和真实值之间的offset扩大了。）
    - AUC只关注正负样本之间的排序，并不关心正样本内部，或者负样本内部的排序。这也体现了AUC的本质：任意个正样本的概率都大于负样本的概率的能力。

- PR

  - PR曲线（Precision-Recall Curve）给出的是不同分类阈值情况下查准率（Precision）和查全率（Recall）的变化曲线
  
- KS

  - KS（Kolmogorov-Smirnov Curve）曲线横轴为不同的分类阈值，纵轴为真正率（TPr）和假正率（FPr）的变化曲线
  - KS值常在**征信评分模型**中用于衡量区分预测正负样本的分隔程度，KS值越大，表明正负样本区分的程度越好
  - 但并非所有的情况KS值都是越高越好的，尤其在征信模型中，如正负样本完全分错的情况下，KS值依旧可以很高。征信模型最期望得到的信用分数分布为正态分布，如果KS值过大，如0.9，就可以认为正负样本分得过开了，不太可能是正态分布，反而比较可能是极端化的分布状态（如U字型），这样的分数就很不好，基本可以认为不可用。

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/eval/ROC PR KS.png) 
</li> 
</ul> 

- Cumulative gains chart
  - 横坐标表示：代表我们样本的百分比，假设有10000个样本，0.1代表1000个，1代表10000个样本
  - 纵坐标表示：代表横轴所代表的那么多样本中，判断正确的比率
  - 曲线含义：采用模型进行预测。y值的分子代表模型预测且预测为正例的人数，分母是整个群体正例人数。
- Silhouette Analysis

#### 多分类问题
- 对于某一个类别
  - True Positive: prediction，label 都属于这个类别
  - True Negative: prediction，label 都不属于这个类别

#### 多标签问题
- 一个样本可以同时属于多个类别 

#### 排序问题
- 应用于推荐、搜索场景，对每个用户生成一个列表，列表里面是模型预测的跟用户最相关的物品
- Precision@k：推荐列表中前k个物品，有多少个在真实列表中
- Mean Average Precision（MAP）：推荐列表中前k个物品，有多少个在真实列表中，考虑位置
- NDCG@k：
  - CG：只考虑到了相关性的关联程度，没有考虑到位置的因素。它是一个搜素结果相关性分数的总和
  - DCG：Discounted 的CG，就是在每一个CG的结果上处以一个折损值，为什么要这么做呢？目的就是为了让排名越靠前的结果越能影响最后的结果
  - NDCG：搜索结果随着检索词的不同，返回的数量是不一致的，而DCG是一个累加的值，没法针对两个不同的搜索结果进行比较，因此需要归一化处理


### 回归问题

- MAE : Mean Absolute Error，平均绝对误差 
- RMSE：Root Mean Square Error，方均根差
  - 对异常点较敏感
  - **改进：使用误差的分位数来代替，如中位数来代替平均数。假设100个数，最大的数再怎么改变，中位数也不会变，因此其对异常点具有鲁棒性**
- MAPE：Mean Absolute Percentage Error， MAPE不仅仅考虑预测值与真实值的误差，还考虑了误差与真实值之间的比例，在某些场景下，比如房价从0.5w到5w之间，0.5预测成1.0与5.0预测成4.5的差距是非常大的



#### Learning Curve

- 学习曲线就是通过画出不同训练集大小时训练集和交叉验证的准确率，可以看到模型在新数据上的表现，进而来判断模型是否方差偏高或偏差过高，以及增大训练集是否可以减小过拟合。

  - **Bias：用所有可能的训练数据集训练出的所有模型的输出的平均值与真实模型的输出值之间的差异**
  - **Variance：不同的训练数据集训练出的模型输出值之间的差异**

- 好像有点鸡肋：不画learning curve，通过比较训练集、验证集和理想的误差，就已经可以判断出是高偏差还是高方差了

- <ul> 
  <li markdown="1"> 
  ![]({{site.baseurl}}/img/machineLearning/eval/learning curve.png) 
  </li> 
  </ul> 



### 参考资料

- https://spark.apache.org/docs/2.3.0/mllib-evaluation-metrics.html
- [腾讯技术工程-机器学习模型可解释性的详尽介绍](https://www.jiqizhixin.com/articles/2019-10-30-9)
- https://blog.csdn.net/simple_the_best/article/details/52296608
- https://blog.csdn.net/pipisorry/article/details/51788927
- [ROC vs PR曲线](https://www.cnblogs.com/JesusAlone/p/9762352.html)
- [标准化SMOTE采样框架实现与应用](https://mp.weixin.qq.com/s?__biz=MzU0MDkwNTEwNA==&mid=2247485127&idx=1&sn=5d87863616235fc78183bd975549afaf&chksm=fb335d38cc44d42e5937fc55f32a805c382ccc4dceb81effec5006d9fb068d739b3cfca99884&mpshare=1&scene=1&srcid=0923TBh912QlEwnLSlcXUB5E&sharer_sharetime=1569246580110&sharer_shareid=49581f7bdbef8664715f595bc62d7044&key=40244416acac1968edd7318efc6e9c268f3418b1c7de1cb1559c9198d1b763de6e061a14eb84f7ab57b6b095e16d5ca68d2d2b5f7cdbb58e633807ea25142c3050a5c32a8464f0c365f945f162f0af00&ascene=1&uin=MjM1OTMwMzkwMA%3D%3D&devicetype=Windows+10&version=62060833&lang=en&pass_ticket=TiPHQC4Wh5A6AqrSE4OyCRA0nErRaUvNEBSXijdw%2F1Z5NrrfASMX97gm21JRq%2FJw)
- https://en.wikipedia.org/wiki/Discounted_cumulative_gain
- https://www.cnblogs.com/by-dream/p/9403984.html
- 
https://mp.weixin.qq.com/s?__biz=MzI1MzY0MzE4Mg==&mid=2247487232&idx=1&sn=ea8113921ce9b048d914b30de7fa264a&chksm=e9d01fc1dea796d7657d6d07d6b62909bd64d971637e05ac726522e8657d8ccfaefc78867659&mpshare=1&scene=1&srcid=0722WEkiaBTzO1t3h5utYNxn&sharer_sharetime=1595504582392&sharer_shareid=49581f7bdbef8664715f595bc62d7044&key=f87c13d2d4a2ca88d3be47a653439eafd87570e4f1fca4ede360a046fc1b6e0056477f5b96065a733b3750167cbee2e2e540cc9b2e3a1cefa7cd4fd531bc0e1a7b7909bdc20b5b492640c415fbd2784e&ascene=1&uin=MjM1OTMwMzkwMA%3D%3D&devicetype=Windows+7+x64&version=62090529&lang=zh_CN&exportkey=ARN6uQa98dLay9aOvu8qxOc%3D&pass_ticket=pnFyhfvRyFnUeQt6s0Iek9TeAxe49aS5%2FTRO%2Bf8l637OOvbI0uku5jeOziKLohZS
  

