---
layout:     post
title:      SIMD
subtitle:   
date:       2023-03-07
author:     bjmsong
header-img: img/simd/title.jpg
catalog: true
tags:

    - 并行计算
---

## SIMD概念

<ul> 
<li markdown="1">
SIMD，即Single Instruction, Multiple Data ，一条指令同时作用于一组数据。
![]({{site.baseurl}}/img/simd/1.png) 
</li> 
</ul> 

现代处理器引入**向量计算单元（vector unit）**来实现数据并行。向量计算单元可以在一组数据上执行向量化指令。比方说，一个512位的向量计算单元可以同时计算16个单精度浮点数的加法。

下面的例子在做两个向量相减，循环的每一步都是相互独立的，因此可以通过SIMD并行。

```c++
for (int i=0; i<n; ++i)
	w[i] = u[i]-v[i];
```

<ul> 
<li markdown="1">
每个算数逻辑单元（ALU）首先加载u[i]，v[i]的数据到寄存器，然后同步执行U-V的指令。
![]({{site.baseurl}}/img/simd/2.png) 
</li> 
</ul> 

如果for循环里面包含**条件判断**，SIMD的**效率较低**。比如下面的例子：

```c++
for (int i=0; i<n; ++i)
	if (u[i]>0)
		w[i] = u[i]-v[i];
	else
		w[i] = u[i]+v[i];
```

<ul> 
<li markdown="1">
算数逻辑单元原本不需要执行所有指令，即下图中的“idle”。
![]({{site.baseurl}}/img/simd/3.png) 
</li> 
</ul> 

- 但是向量计算单元必须同时执行指令，这种情况下会采用下面的步骤进行，有部分计算是浪费的：
  1. 每个算数逻辑单元比较`U[i]`和`V[i]`的值，并设置flag
  2. 每个算数逻辑单元计算`U-V`指令，如果flag为true，则存储结果到W
  3. 每个算数逻辑单元计算`U+V`指令，如果flag为false，则存储结果到W



## 微处理器的向量化

<ul> 
<li markdown="1">
x86 CPU从1997年开始支持SIMD操作，随后SSE/AVX/AVX-512等指令集相继问世。
![]({{site.baseurl}}/img/simd/4.png) 
</li> 
</ul> 



| 指令集  | 寄存器的大小 | 提出时间 |
| ------- | ------------ | -------- |
| SSE     | 128          | 1999年   |
| AVX     | 256          | 2011年   |
| AVX-512 | 512          | 2015年   |


查看CPU是否支持AVX指令集

```shell
cat /proc/cpuinfo | grep avx
```

- [在编译时判断是否支持SSE/SSE2/AVX/AVX2/AVX-512指令](https://blog.csdn.net/qq_20880415/article/details/105967740)



### Intrinsic Function

SSE/AVX 指令集允许使用汇编指令集去操作XMM和YMM寄存器，但直接使用AVX 汇编指令编写汇编代码并不是十分友好而且效率低下。于是，`intrinsic function` 应运而生。`Intrinsic function` 类似于 high level 的汇编，开发者可以无痛地将 `instinsic function`同 C/C++ 的高级语言特性（如分支、循环、函数和类）无缝衔接。

比如，两个256 bit的AVX寄存器加法可以这样实现：

```c++
__m256 a, b, c;         // declare AVX registers
...                     // initialize a,b,c
c = _mm256_add_ps(a,b);  // c[0:8] = a[0:8] + b[0:8]
```

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/simd/5.png) 
</li> 
</ul> 

下面是普通的矩阵乘法实现：

```c++
void plain_tmm(float* A, float* B, float* C, uint64_t M, uint64_t L,  uint64_t N){
for (uint64_t i = 0; i < M; i++)
    for (uint64_t j = 0; j < N; j++) {
        float accum = 0;
        for (uint64_t k = 0; k < L; k++)
            accum += A[i*L+k]*Bt[j*L+k];    // Bt是B的转置矩阵
        C[i*N+j] = accum;
    }
}
```

下面是使用AVX向量化的实现：

```c++
#include <immintrin.h>

void avx2_tmm(float* A, float* B, float* C, uint64_t M, uint64_t L,  uint64_t N){
    for (uint64_t i=0; i<M; ++i)
        for (uint64_t j=0; j<N; ++j)
            // delcare vector of type __m256 with all elements set to zero
            __m256 X = _mm256_setzero_ps();     
    		for (uint64_t k=0; k<L; k+=8)
            {
// Load 256-bits from memory into dst. mem_addr must be aligned on a 32-byte boundary
                const __m256 AV = _mm256_load_ps(A+i*L+k);
                const __m256 BV = _mm256_load_ps(B+j*L+k);
// Multiply elements in AV and BV, add the intermediate result to packed elements in X
                X = _mm256_fmadd_ps(AV, BV, X);
            }
    		C[i*N+j] = hsum_avx(X);    // hsum_avx: user-defined function
}
```

`_mm256_load_ps`函数从矩阵加载8个内存连续的单精度浮点数到256 bit寄存器。同时要求被加载的矩阵**内存对齐**，也就是说，**必须放在连续的且首地址为32的倍数的内存空间中**，这可以通过`_mm_malloc`函数来实现：

```c++
auto A = static_cast<float*>(_mm_malloc(M*L*sizeof(float), 32));
auto B = static_cast<float*>(_mm_malloc(N*L*sizeof(float), 32));
```

<ul> 
<li markdown="1">
_mm256_fmadd_ps函数的计算过程如下图：
![]({{site.baseurl}}/img/simd/6.png) 
</li> 
</ul> 

`CMake`设置

```cmake
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -march=native")
```

<ul> 
<li markdown="1">
AVX向量化的版本，会带来数倍的速度提升（7584ms->1859ms）
![]({{site.baseurl}}/img/simd/7.png) 
</li> 
</ul> 



## AOS、SOA

<ul> 
<li markdown="1">
![]({{site.baseurl}}/img/simd/8.png) 
</li> 
</ul> 



## GCC中的向量化

GCC8.2.0中关于向量化操作的选项有：-ftree-loop-vectorize、-ftree-slp-vectorize、-ftree-loop-if-convert、-ftree-vectorize、-fvect-cost-model=model、-fsimd-cost-model=model。前两个向量化选项默认情况下在`-O3`中已启用



## 第三方库

- SLEEF ：开源的SIMD优化实现
- simd： https://github.com/ermig1979/Simd


