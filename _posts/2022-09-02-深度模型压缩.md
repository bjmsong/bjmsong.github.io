---
layout:     post
title:      深度模型压缩与加速
subtitle:   
date:       2022-09-02
author:     bjmsong
header-img: 
catalog: true
tags:
    - 模型优化与部署
---
《A Survey of Model Compression and Acceleration for Deep Neural Networks》
《Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding》
https://awesomeopensource.com/projects/model-compression
https://github.com/cedrickchee/awesome-ml-model-compression
https://github.com/j-marple-dev/model_compression
https://github.com/SpursLipu/YOLOv3v4-ModelCompression-MultidatasetTraining-Multibackbone
https://github.com/memoiry/Awesome-model-compression-and-acceleration
https://github.com/chester256/Model-Compression-Papers

## MIT公开课 TinyML and Efficient Deep Learning
https://www.bilibili.com/video/BV1uK411m7f6/?is_story_h5=false&p=1&share_from=ugc&share_medium=android&share_plat=android&share_session_id=11c52362-cb9b-4c45-a9ac-2f4a3091cc1a&share_source=WEIXIN&share_tag=s_i&timestamp=1669178663&unique_k=4FcyhYZ

## Architecture Design
- MobileNet，yolo，ShuffleNet
- 矩阵分解
    - ALBERT
- 权值共享
- 分组卷积
- 分解卷积,小型CNN
https://blog.csdn.net/briblue/article/details/84995553
https://zhuanlan.zhihu.com/p/49465950
- 全局平均池化代替全连接层

## Network Pruning 模型剪枝
- https://pytorch.org/tutorials/intermediate/pruning_tutorial.html
- 用NNI、TinyNeuralNetwork 等框架对模型进行剪枝，并阅读其源码了解常用的剪枝方法
- prune redundant weights or neurons
- importance of weight: L1,L2
- importance of neuron: the number of times it wasn't zero on a given dataset
- 将权重矩阵中不重要的参数设置为0，结合稀疏矩阵来进行存储和计算
- 为了保证performance，需要一小步一小步地进行迭代剪枝
- 一般是prune neuron：神经元直接拿掉
- prune weight存在的问题
    - 连接直接拿掉，不容易实现
    - weight设为0，容易实现，方便加速，但是模型没有真正压缩，并没有得到加速

## Knowledge Distillation 蒸馏
- student模型学习teacher模型的输出
- 没太有用？
- 《Distilling the Knowledge in a Neural Network》
- DistilBERT

## Parameter Quantization 量化
《Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference》
- https://pytorch.org/docs/stable/quantization.html?highlight=quantization#dynamic-quantization
- 实践
    + https://pytorch.org/blog/quantization-in-practice/
    + https://www.tensorflow.org/model_optimization/guide/quantization/training?hl=zh-cn
    + https://www.tensorflow.org/lite/performance/post_training_quantization?hl=zh-cn
    + https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/how_tos/quantization/index.md
- https://pytorch.org/docs/stable/quantization.html
- 伪量化
    - 利用低精度来保存每一个网络参数，同时保存拉伸比例scale和零值对应的浮点数zero_point
    - 存储时使用了低精度进行量化，但推理时会还原为正常高精度
    - 伪量化可以实现模型压缩，但对模型加速没有多大效果
- 聚类与伪量化
    - 进阶：霍夫曼编码
        - Represent frequent clusters by less bits, represent rare clusters by more bits
- 定点化
    - 与伪量化不同的是，定点化在推理时，不需要还原为浮点数
    - 《Deep learning with limited numerical precision》
- 二值化
《Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1》
https://blog.csdn.net/elaine_bao/article/details/50950969
- PTQ：需要插入观察op来收集每一层的激活分布以及权重分布
- QTA：需要插入fake量化节点来模拟量化
- Apex 混合精度
https://zhuanlan.zhihu.com/p/79887894
- 参考资料
    - 消费级GPU运行1760亿参数大模型
    https://mp.weixin.qq.com/s/gyLzQhW0mZxKXtCUau3ScQ
    https://github.com/timdettmers/bitsandbytes
    - https://blog.csdn.net/WZZ18191171661/article/details/103332338/
    - https://jilei-hou.github.io/2022/06/18/%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96/
    - 社区分享 | TensorFlow 模型优化：模型量化
    https://mp.weixin.qq.com/s/9QeVVESP3_rBZ6n_D96lwg
    - https://zhuanlan.zhihu.com/p/505570612
    - https://www.zhihu.com/question/421743958
    
## Dynamic Computation
- adjust the computation power it need
- possible solution
    - Train multiple classifiers
    - Classifiers at the intermedia layer


## TensorFlow 模型优化工具包
https://www.tensorflow.org/model_optimization?hl=zh-cn
https://mp.weixin.qq.com/mp/appmsgalbum?action=getalbum&album_id=1642498502104547335&__biz=MzU1OTMyNDcxMQ==#wechat_redirect
- 量化
- 剪枝

## 阿里妈妈搜索广告CTR模型的“瘦身”之路
https://mp.weixin.qq.com/s/fOA_u3TYeSwAeI6C9QW8Yw

## 《Training Deep Nets with Sublinear Memory Cost》
- 用低于线性复杂度就可以训练更深模型的内存优化算法，直接把 backward 所需要的内存量从 O(N) 降低到 O(sqrt(N))
https://github.com/Lyken17/pytorch-memonger
https://zhuanlan.zhihu.com/p/62270652

## 参考资料
- 李宏毅：模型压缩系列讲解
https://www.bilibili.com/video/BV1LE411Z76J?spm_id_from=333.337.search-card.all.click&vd_source=7798c62f92ce545f56fd00d4daf55e26
http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20
    - 第七课
- 《Stripes: Bit-serial deep neural network computing》
- 《Minerva: Enabling low- power, highly-accurate deep neural network accelerators》
- https://www.bilibili.com/video/BV1364y1d7Ks?is_story_h5=false&p=1&share_from=ugc&share_medium=android&share_plat=android&share_session_id=59556101-a815-4452-bc93-b8e4ee3797b3&share_source=WEIXIN&share_tag=s_i&timestamp=1661949215&unique_k=iw6RbGx
- http://eyeriss.mit.edu/2019_neurips_tutorial.pdf?ich_args2=526-06113205060278_e0b61138dc2d908aa0766d50302e6d8a_10001002_9c896324d5cbf0d49239518939a83798_92e0a859ed6aa28355c3deea32562911
- https://zhuanlan.zhihu.com/p/421154873
- https://zhuanlan.zhihu.com/p/138059904
- https://www.zhihu.com/question/329372124/answer/2675692342


