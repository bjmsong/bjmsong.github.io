---
layout:     post
title:      Spark海量数据相似度计算
subtitle:   
date:       2021-04-13
author:     bjmsong
header-img: img/spark/Spark_logo.png
catalog: true
tags:
    - Spark
---
## 场景
- 海量向量之间的相似度计算（user&item，item&item）
- 直接两两计算的话，会产生笛卡尔积，数据量非常大

## 降维：简洁有效

## 矩阵运算:精确计算
https://www.cnblogs.com/wwxbi/p/6815685.html
https://towardsdatascience.com/preserve-row-indices-with-spark-matrix-multiplication-8007e21ea28f
https://stackoverflow.com/questions/33558755/matrix-multiplication-in-apache-spark

## LSH：近似计算
https://zhuanlan.zhihu.com/p/61200936
https://bjmsong.github.io/2020/04/22/%E8%BF%91%E4%BC%BC%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2/
### faiss

- 其它：sptag，milvus（qps是多少）

## 行/列之间相似度（可应用于ItemCF场景）
https://blog.csdn.net/qq_31032181/article/details/90599441
https://zhuanlan.zhihu.com/p/59460929
https://stackoverflow.com/questions/43921636/apache-spark-python-cosine-similarity-over-dataframes
https://stackoverflow.com/questions/47010126/calculate-cosine-similarity-spark-dataframe
https://stackoverflow.com/questions/43921636/apache-spark-python-cosine-similarity-over-dataframes?rq=1

## 单机
- numpy可以跑吗
- spark不如单机，极客时间里面也有说

## 其它
https://www.zhihu.com/question/265901363