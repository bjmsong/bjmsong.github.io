---
layout:     post
title:      DLRM
subtitle:   
date:       2022-09-06
author:     bjmsong
header-img: 
catalog: true
tags:
    - 深度模型加速
---
## 官方文档
- https://arxiv.org/abs/1906.00091
- https://ai.facebook.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/
- https://www.youtube.com/watch?v=DFrCEvPgEcQ&ab_channel=OpenComputeProject

## 解读
- 参考
    - https://zhuanlan.zhihu.com/p/82839874
    - https://www.infoq.cn/article/isbHku4p*C4KZ49JIkLy
- 模型中规中矩
    - 离散特征：embedding
    - 连续特征：通过mlp处理成跟离散特征一样的长度
    - 特征交叉
- 并行训练
    - Embedding部分采用模型并行
        - 绝大部分参数在Embedding部分
        - 在一个device或者说计算节点上，仅有一部分Embedding层参数，每个device进行并行mini-batch梯度更新时，仅更新自己节点上的部分Embedding层参数
    - MLP和interactions部分采用数据并行
        - 参数少，计算量大
        - 每个device上已经有了全部模型参数，每个device上利用部分数据计算gradient，再利用allreduce的方法汇总所有梯度进行参数更新
    - PyTorch/caffe2不支持模型并行+数据并行
- Data
    - Random
    - synthetic
    - public data sets
- Experience
    - 训练平台：CPU+GPU

## 源码
- https://github.com/facebookresearch/dlrm


## 参考资料
