---
layout:     post
title:      样本不平衡问题
subtitle:   
date:       2020-02-19
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---

### 样本非平衡带来的问题
- 算法工程师小王拿到一个项目，用机器学习模型预测产品是否有缺陷。经过训练，模型得到了99%的Accuracy（准确率），小王很开心，兴冲冲地模型拿去上线了，预感升职加薪在向自己招手

- 然而，模型上线了一段时间后，并没起到什么效果，眼看老板的脸色越来越不好看了，小王赶紧去分析原因。

- 经过一通分析，小王恍然大悟：样本中，缺陷产品的占比是1%，而模型的预测结果是对所有产品都预测为正常，这样就可以达到99%的Accuracy（Accuracy的定义是分类正确的样本占总样本的比例）

- 不幸中的万幸，这只是一个预测产品缺陷的模型，还好不是用来做癌症预测。


### 样本非平衡问题的评价指标

#### PR曲线
- 好的评价指标可以帮助我们更全面地了解我们的模型
- 像上面的问题，画一下混淆矩阵,其实就比较清晰了，令产品有缺陷的label为1

  |   实际/预测   | 1    | 0    |    Total  |
  | ---- | ---- | ---- | ---- |
  | 1    |   0   |  1    |    1  |
  | 0    |   0   |  99    |    99  |
  | Total     |  0   |  100    |      |

  - Precesion = 0, Recall = 0, F1 = 0　＝> so bad
- 因此：PR曲线，综合观察Precesion/Recall/F1指标，可以帮助我们更全面了解模型的好坏

#### AUC
- 然而，有文献指出，ROC曲线相比PR曲线有一个非常好的特性：就是当正负样本分布发生变化的时候，ROC曲线的形状能够基本保持不变，而PR曲线的形状会发生较剧烈的变化 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/eval/样本剧烈变化导致的PRCvsROC.jpg) 
</li> 
</ul> 

  - 同一个模型，在测试集正负样本均衡的情况下PRC表现很好，在正负样本不均衡的情况下PRC表现很差。但是ROC都是一样的。说明当正负样本不均衡的情况下，不能用PRC来衡量模型效果，而要用ROC衡量
  - 原因是FPR 和 TPR (Recall) 只与真实的正例或负例中的一个相关（可以从他们的计算公式中看到），而Precision则同时与真实的正例与负例都有关
  - **正由于AUC对分值本身不敏感，故常见的正负样本采样，并不会导致auc的变化。比如在点击率预估中，处于计算资源的考虑，有时候会对负样本做负采样，但由于采样完后并不影响正负样本的顺序分布。即假设采样是随机的，采样完成后，给定一条正样本，模型预测为score1，由于采样随机，则大于score1的负样本和小于score1的负样本的比例不会发生变化**
  - 业界对于CTR预估基本还是采用AUC
  - https://blog.csdn.net/Dby_freedom/article/details/89814644

#### 自定义评价函数

```python
xgb.train(params, dtrain, num_rounds, watchlist, feval=misclassified, maximize=False)

def misclassified(pred_probs, dtrain):

  labels = dtrain.get_label() # obtain true labels

  preds = pred_probs > 0.5 # obtain predicted values

  return 'misclassified', np.sum(labels != preds)
```


### 解决方法

- 首先排除是不是数据采样的问题：真实数据中正负样本的比例是怎么样的？如果真实数据确实不平衡，再来看下面的方法。

#### 最有效的方法：增加更多有“区分性”的特征

<ul> 
<li markdown="1"> 
好的特征可以帮助我们更好地区分不同类别的样本，哪怕不同类别的比例差别很大。 -- 特征工程才是王道
![]({{site.baseurl}}/img/machineLearning/imbalanced/add new feature.jpeg) 
</li> 
</ul> 

#### 重采样
- 常用方法 
  - 对数据多的那一类样本进行降采样：降低采样比例
  - 对数据少的那一类样本进行过采样：提高采样比例
  - 合成少类样本：`smote`
- 正负样本的比例多少合适
- **改变正负样本比例的做法很危险，要注意带来的影响，不适用于所有问题**
  - 一定会降低Accracy
- 但是如果我们只关注其中某一类的预测效果（如下图中的C1类别），采样方法是有效的

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/imbalanced/欠采样.jpeg) 
</li> 
</ul> 

- 对于像Naive Bayes这样的模型，调整不同类别样本的采样率可以影响模型的loss

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/imbalanced/bayes.png) 
</li> 
</ul> 

#### 训练集，验证集、测试集，哪个需要采样 ？
- 采样训练集
- 不采样测试集：如果采样测试集，会高估真实数据集的效果
- 不采样验证集：验证集需要跟测试集保持一致
https://stats.stackexchange.com/questions/105797/training-and-testing-on-unbalanced-data-set
https://stats.stackexchange.com/questions/258853/training-data-is-imbalanced-but-should-my-validation-set-also-be
https://datascience.stackexchange.com/questions/32818/train-test-split-of-unbalanced-dataset-classification
https://datascience.stackexchange.com/questions/61858/oversampling-undersampling-only-train-set-only-or-both-train-and-validation-set


#### 自定义loss function
  
- Use a asymmetric cost function to artificially balance the training process ： 不同类别的样本预测错误的损失是不一样的
- 例如一开始的例子中， Loss（有缺陷的产品预测为正常产品） >> Loss（正常产品预测为有缺陷的产品）

#### 正常训练模型，在预测阶段，对不同类别的预测结果乘以不同的权重

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/imbalanced/重新定义loss.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/imbalanced/预测结果重新赋予权重.jpeg) 
</li> 
</ul> 


#### XGBOOST 
- If you care only about the overall performance metric (AUC) of your prediction
    - Balance the positive and negative weights via `scale_pos_weight` ：  多类样本数量/少类样本数量
      - The scale_pos_weight value is used to scale the gradient for the positive class.　This has the effect of scaling errors made by the model during training on the positive class and encourages the model to over-correct them。
    - Use `AUC` for evaluation
- If you care about predicting the right probability ：真实的概率，而不是样本间的相对顺序
  - In such a case, you cannot re-balance the dataset
  - Set parameter `max_delta_step` to a finite number (say 1) to help convergence
- min_child_weight 设的小一点 保证少类样本也可以单独出现在叶子节点中
  - 个人经验
- https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html
- https://machinelearningmastery.com/xgboost-for-imbalanced-classification/

#### 调整类型权重、样本权重
- 以sklearn的逻辑回归为例，可以调整样本权重（`sample_weight`）和类别权重（`class_weight`）参数
- https://zhuanlan.zhihu.com/p/75679299 
  

#### One Class Learning
- Just assume your data has a few real points (the ones) and lots of random noise that doesn't physically exists leaked into the dataset (anything that is not a one is noise). Use an algorithm to denoise the data instead of a classification algorithm
- 当成一个异常检测的问题


### 参考资料

- https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights
- https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28
- https://github.com/ZhiningLiu1998/awesome-imbalanced-learning
- python package ： `imbalanced-learn`
- paper
  - Special issue on learning from imbalanced datasets
  - Data Mining for Imbalanced Datasets: An Overview
  - Analysing the classification of imbalanced data-sets with multiple classes: Binarization techniques and ad-hoc approaches
  - Evolutionary Undersampling for Classification with Imbalanced Datasets: Proposals and Taxonomy
  - On the Classification of Imbalanced Datasets
- [标准化SMOTE采样框架实现与应用](https://mp.weixin.qq.com/s?__biz=MzU0MDkwNTEwNA==&mid=2247485127&idx=1&sn=5d87863616235fc78183bd975549afaf&chksm=fb335d38cc44d42e5937fc55f32a805c382ccc4dceb81effec5006d9fb068d739b3cfca99884&mpshare=1&scene=1&srcid=0923TBh912QlEwnLSlcXUB5E&sharer_sharetime=1569246580110&sharer_shareid=49581f7bdbef8664715f595bc62d7044&key=40244416acac1968edd7318efc6e9c268f3418b1c7de1cb1559c9198d1b763de6e061a14eb84f7ab57b6b095e16d5ca68d2d2b5f7cdbb58e633807ea25142c3050a5c32a8464f0c365f945f162f0af00&ascene=1&uin=MjM1OTMwMzkwMA%3D%3D&devicetype=Windows+10&version=62060833&lang=en&pass_ticket=TiPHQC4Wh5A6AqrSE4OyCRA0nErRaUvNEBSXijdw%2F1Z5NrrfASMX97gm21JRq%2FJw)
- [非平衡数据集](https://www.kaggle.com/data/46744)  

