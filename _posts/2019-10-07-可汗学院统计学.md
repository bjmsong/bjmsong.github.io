---
layout:     post
title:      可汗学院统计学
subtitle:   
date:       2019-10-07
author:     bjmsong
header-img: img/Linear Algebra/math.jpg
catalog: true
tags:
    - 数学
---

> 可汗学院，每个视频都在10min左右，每个视频讲一个知识点。可以随时暂停、快进、复习之前的知识点。循序渐进，通过实例讲解知识点，而不是一上来就一堆公式和定理，适合入门。
> 萨尔曼·可汗老师是一位很有理想的教育家，MIT/Harvard背景，有兴趣可以看下他的[教育理想](https://www.bilibili.com/video/av11580545/)

### 基本分类

- 描述统计学：描述一堆数据
- 推论统计学：通过对样本的分析，推断总体



### 符号定义

$$\mu$$:总体均值

$$\bar{x}$$:样本均值

$$\sigma^2$$:总体方差

$$S^2$$:样本方差

  

### 描述统计学

- 集中趋势：均值、中位数、众数

- 离散趋势：方差($$\sigma^2$$)、标准差（$$\sigma$$）、极差

  - 总体方差简化写法

    $$\frac{\sum(x_i^2)}{N}-\mu^2$$

  - 样本方差（sample variance）

    - 总体（population）方差的无偏估计

      $$S^2=S_{n-1}^2=\frac{\sum^n_1(x_i-\bar{x})^2}{n-1}$$

      其中，n是样本个数，$$\bar{x}$$是样本平均值

- 条形图、线型图、饼图、茎叶图、箱线图



### 随机变量

- 跟传统的可求解的变量不同，更像是从随机过程映射到数值的函数

- 通常用大写字母表示，例如：

  ​	
  
  - $$X=
    \begin{cases}
    0& \text{if rain tomorrow}\\
    1& \text{if not rain tomorrow}
    \end{cases}$$
  
    
  
   - 骰子抛出的数值
  
   - 抛硬币的结果
  
   - 明天下雨的毫米数
  
- 离散型，连续型



### 期望值

- 随机变量可能的取值×对应的概率的总和
- 随机变量的期望值就是随机变量总体的均值，因为总体没法给出样本的数量（无穷），所以采取概率的方式计算
- 期望值不一定是概率最大的取值
- 大数定律：样本数量趋于无穷时，样本均值趋近于随机变量的期望值
  - 赌徒谬误（以掷硬币为例）：如果前面得到正面的次数多，后面得到的反面次数会多
    - It‘s Wrong!
    - 大数定理不关心有限次试验，每次试验都是独立的



### 概率密度分布

#### 概率密度曲线的理解

- 纵轴是随机变量等于横轴的概率

- **对于连续型随机变量而言，P(X=某个特定值)约等于0，P(X属于某个范围)=概率密度函数曲线下的面积 (即两点间的定积分)**

- 概率密度曲线下方的面积等于1

#### 几种典型的概率密度分布
- 均匀分布

- 二项分布（伯努利分布）

  - 伯努利试验：每次试验中只能由两种可能的结果（如抛硬币）

  - 重复n次伯努利试验的离散概率分布，**连续情况下将得到正态分布**

  - n次试验，成功x次的概率：

    $$f(x)=C_n^xp^x(1-p)^{(n-x)}$$	

  - 之所以叫“二项”分布，因为概率值是二项式$$(x+y)^n$$的展开形式

  - 期望值 ：  $$np$$

  - 方差：   $$np(1-p)$$

- 泊松分布

  - 估计某件事件在特定时间段或空间中发生的次数。例如：一小时内通过的汽车数，100英里水管上发生泄漏的个数。

  - 泊松试验的假设 

    - 在任意两个长度相等的区间上，事件发生的概率是相同的
    - 事件在任一区间上是否发生与事件在其他区间上是否发生是相互独立的

  - 泊松概率函数

    $$f(x)=\frac{\mu^xe^{-\mu}}{x!}$$

    $$f(x)$$代表事件在一个区间上发生x次的概率，$$\mu$$代表事件在一个区间上发生次数的数学期望或均值

  - 和二项分布的关系

    - 将时间无限分割，就是二项分布，可以推导出泊松分布的公式

- **正态分布**（高斯分布，钟形曲线） 

  - 概率密度函数

    $$f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$

  - 二项分布是正态分布的很好近似

  - $$\frac{x-\mu}{\sigma}$$:  z分数，距离均值几个标准差

  - 累积分布函数（CDF）：值小于x范围的概率

  - 一个/两个/三个标准差范围内：68%/95%/99.7%

  - 峰度：峰度大于3--峰值比正态分布高

  - 双峰/多峰分布

  - 右偏分布/左偏分布

    - 偏度
    - 长尾分布

- Beta分布

  - 对于硬币或者骰子这样的简单实验，我们事先能很准确地掌握系统成功的概率。然而通常情况下，系统成功的概率是未知的。为了测试系统的成功概率，我们做n次试验，统计成功的次数k，于是很直观地就可以计算出。然而由于系统成功的概率是未知的，这个公式计算出的只是系统成功概率的最佳估计。也就是说实际上也可能为其它的值，只是为其它的值的概率较小。
  - 例如，有某种特殊的硬币，我们事先完全无法确定它出现正面的概率。然后抛10次硬币，出现5次正面，于是我们认为硬币出现正面的概率最可能是0.5。但是即使硬币出现正面的概率为0.4，也会出现抛10次出现5次正面的情况。因此我们并不能完全确定硬币出现正面的概率就是0.5，所以也是一个随机变量，它符合Beta分布。
  - Beta分布是一个连续分布，由于它描述概率的分布，因此其取值范围为0到1。 Beta分布有和两个参数$$\alpha$$,$$\beta$$
  - Beta分布的均值是$$\frac{\alpha}{\alpha+\beta}$$，通过先验信息确定（如一般硬币为正面的概率为0.5）
  - 每次试验成功$$\alpha$$加1，失败则$$\beta$$加1
  - 对于一个我们不知道概率是什么，而又有一些合理的猜测时，beta分布能很好的作为一个表示概率的概率分布。

  <ul>  

  <li markdown="1"> 

  ![]({{site.baseurl}}/img/Statistics/beta.png) 

  </li> 

  </ul>

  - beta分布特征

    - α + β 的值越大，分布曲线越窄，也就是越集中。

    - α/(α + β) 的值是 beta 分布的均值（期望值），它的值越大， beta 分布的中心越靠近 1，否则越靠近 0 。

      
    
### 中心极限定理
- **最基础、最重大意义的概念之一，也是正态分布得以大量应用的原因**
- 大量(相互独立随机变量的)样本均值服从正态分布
  - 随机变量来自**任何**良好定义了均值和方差的分布，不管该分布是连续还是离散的
- 大量随机事件之和服从正态分布
- 若原分布的均值为$$\mu$$,标准差为$$\sigma$$,则每次抽样n个样本，这些样本均值组成的分布（也称为 sampling distribution of the sample mean）:
  - 平均值：$$\mu_{\bar{x}}=\mu$$
  - 标准差：$$\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$$

#### 常见应用场景
- 从总体中抽样一个样本，可以通过样本的平均值，标准差来推断总体的平均值处于某个范围的概率。
- 置信区间(Confidence interval)/误差范围（margin of error）
  -  从总体(均值为$$\mu$$, 方差为$$\sigma^2$$)中抽样一个样本（样本数量为n），这个样本属于" sampling distribution of the sample mean"这个分布，满足正态分布，均值为$$\mu_\bar{x}$$（=$$\mu$$）,方差为$$\sigma_\bar{x}^2$$
  - 计算样本的平均值$$\bar{x}$$、方差$$S^2$$
  - 以样本方差作为整体方差 无偏估计**，因为" sampling distribution of the sample mean"方差和整体方差满足$$\sigma_{\bar{x}}^2=\frac{\sigma^2}{n}$$，可以得到$$\sigma_\bar{x}$$
    - 只有样本数量n较大（n>30）的情况下，样本方差的无偏估计才比较准
    - **如果n<30，则认为样本的均值分布服从t分布（而不是正态分布）**，自由度是n-1
      - t分布非常类似正态分布，只是两端尾部更肥
  - 因为P（$$\bar{x}$$在$$\mu_\bar{x}$$两倍标准差内）=95%，则P（$$\mu_\bar{x}$$在$$\bar{x}$$两倍标准差内）=95%，即可以由样本的平均值得到总体的平均值的(95%)置信区间。



### 假设检验 

- 在假设检验中，我们先对总体参数做一个尝试性的假设。该尝试性的假设称为**原假设**/零假设（null hypothesis），记为$$H_0$$。然后，定义另一个与原假设的内容完全对立的假设，记为$$H_a$$，称为备择假设（alternative hypothesis ）。假设检验的过程就是根据样本数据对这两个对立的假设进行检验。

- **首先，假设原假设正确，计算得到该样本的概率。如果概率非常非常小（小于p值 ），就可以拒绝原假设，从而备择假设正确。**

- 单侧检验一般形式如下：

  - 下侧检验

    $$H_0:\mu\geq\mu_0 ,\quad H_a:\mu<\mu_0$$

  - 上侧检验

    $$H_0:\mu\leq\mu_0 ,\quad H_a:\mu>\mu_0$$

- 双侧检验（two-tailed test）一般形式如下：

  $$H_0:\mu=\mu_0 , \quad H_a:\mu\neq\mu_0$$

- 第一类错误：拒绝了正确的原假设

  - 根据假设检验，如果得到某样本的概率为$$p_1$$,小于p-value，我们就可以拒绝原假设。但是原假设仍然有可能是成立的，也就有可能犯了第一类错误，犯错的概率是$$p_1$$。

- 第二类错误：接受了错误的原假设



### 均值之差的分布

- 完全独立（不相关）的随机变量X，Y 

- 若Z=X+Y，那么： 

  $$E(Z)=E(X)+E(Y)=\mu_X+\mu_Y$$
  
  $$Var(Z)=Var(X)+Var(Y)=\sigma_X^2+\sigma_Y^2$$
  
- 若Z=X-Y，那么：

  $$E(Z)=E(X)-E(Y)=\mu_X-\mu_Y$$

  $$Var(Z)=Var(X)+Var(Y)=\sigma_X^2+\sigma_Y^2$$  

  **注意，方差还是和**

- 若$$Z=\bar{X}-\bar{Y}$$，$$\bar{X}$$是X中抽样的样本的均值,那么，Z也满足正态分布，并且：

  $$\mu_Z=\mu_\bar{X}-\mu_\bar{Y}$$

  $$\sigma_{\bar{X}-\bar{Y}}^2=\sigma_{\bar{X}}^2+\sigma_{\bar{Y}}^2$$
  
  - **若$$\bar{X}$$是实验组，$$\bar{Y}$$是对照组 ，则可以通过计算Z的置信区间，判断实验组和对照组是否有显著差异（如：Z在95%置信区间内大于0）**
    - 也可以通过假设检验的方法来判断，实验组和对照组是否有显著差异



### 线性回归

- 最小二乘法（least square method）

  - 最小化点到直线的平方误差之和，即偏导等于0

  - 求得直线$$y=mx+b$$的参数

    $$m=\frac{\bar{x}\bar{y}-\bar{xy}}{\bar{x}^2-\bar{x^2}}$$
    
    $$b=\bar{y}-m\bar{x}$$

- 决定系数$$R^2$$

  - y的总波动

    $$SE_{\bar{y}}=(y_1-\bar{y})^2+(y_2 -\bar{y})^2+...(y_n -\bar{y})^2$$

  - 误差，即回归线没有描述的波动

    $$SE_{Line}=(y_1-(mx_1+b))^2+(y_2 -(mx_2+b))^2+...(y_n -(mx_n+b))^2$$

  - y的总波动有多少被直线所描述，即决定系数(coefficient of determination)$$R^2$$

    $$1-\frac{SE_line}{SE_\bar{y}}$$

- 协方差   

  $$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=E[XY]-E[X]E[Y]=\bar{XY}-\bar{X}\bar{Y}$$
  
  - 线性回归的系数可以改写成协方差形式
  
    $$m=\frac{Cov(X,Y)}{Cov(X,X)}=\frac{Cov(X,Y)}{Var(X)}$$



### $$\chi^2$$分布

- 从标准正态分布中抽样，然后对值进行平方，这样一些随机变量平方之和，得到的分布
- 自由度：多少个随机变量平方求和
  - 如 $$Q = X_1^2+X_2^2$$ : 自由度=2
- 应用：**衡量观测值和预计值之间的误差**，即预测是否准确

- 皮尔逊$$\chi^2$$检验
  
  - 构造原假设，备择假设 
  - 构造$$\chi^2$$统计量，该统计量的每一项是观测值和预计值的误差的平方（再标准化）
  - 根据$$\chi^2$$分布，计算得到该统计量的概率，如果小于p-value，则可以推翻原假设
  
- 列联表$$\chi^2$$检验



### 方差分析

-  场景：m组数据，每组有n个点，各组数据可以看作是来自各组总体的抽样
-  求：各组的总体均值是否相等
-  总平方和（SST: Total sum of squares）： 每个点同总均值的距离平方和，自由度：mn-1
   -  组内平方和（SSW）：每个点同各组均值的距离平方和，自由度：m(n-1)
   -  组间平方和（SSB）： 各组均值同总均值的距离平方和，自由度：m-1
   -  SST = SSW + SSB
-  F统计量假设检验
   -  F分布：两个$$\chi^2$$分布之比
   -  F统计量：(组间平方和除以组间自由度)/(组内平方和除以组内自由度)，即$$\frac{\frac{SSB}{MSB}}{\frac{SSW}{MSW}}$$



### 相关性和因果性 

- 相关性：A和B有可能被同时观测到
  - A并不一定是发生B的原因，可能有其它的原因导致A和B的发生
- 因果性：A导致B



### 演绎推理（deductive reasoning）

- 从一些数据和事实出发，演绎得到其他正确的事实
- 演绎推理知道肯定正确
- 例如：解方程



### 归纳推理（inductive reasoning）

- 寻找规律或趋势，然后推广
- 归纳推理在推广时，并不确定趋势是否会继续，只是假设它会继续
- 例如：时间序列预测



### 参考资料

- 《商务与经济统计》
- https://blog.csdn.net/a358463121/article/details/52562940






