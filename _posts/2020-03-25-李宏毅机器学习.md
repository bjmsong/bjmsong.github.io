---
layout:     post
title:      李宏毅机器学习
subtitle:   
date:       2020-03-25
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---

> 入门最佳课程



<ul> 
<li markdown="1"> 
Structured Learning:除分类、回归以外的机器学习任务，如语音识别、机器翻译
![]({{site.baseurl}}/img/machineLearning/机器学习概貌.png) 
</li> 
</ul> 

### Bias & Variance

<ul> 
<li markdown="1"> 
机器学习的误差来源于两个方面：bias，variance。每次采样一批样本做预测，bias是预测的期望值和真实值的差距，variance是单个预测结果和预测的期望值的差距。
![]({{site.baseurl}}/img/machineLearning/bias_variance.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/bias.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/bias_variance2.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
诊断误差的来源，才能找到提升模型的方法    
![]({{site.baseurl}}/img/machineLearning/large_bias.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/large_variance.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/cross_validation.png) 
</li> 
</ul> 



### 梯度下降

<ul> 
<li markdown="1"> 
Loss Function要选凸函数：只有全局最优，没有局部最优
![]({{site.baseurl}}/img/machineLearning/梯度下降.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/梯度下降公式.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
做梯度下降要画loss随参数更新的变化趋势图
![]({{site.baseurl}}/img/machineLearning/learning_rate.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/adaptive_learning_rate.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/adagrad.png) 
</li> 
</ul> 

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/adagrad2.png) 
</li> 
</ul> 

- 目前比较好的方法是：`Adam`

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/随机梯度下降.png) 
</li> 
</ul> 





### 分类



### 逻辑回归



### Deep Learning