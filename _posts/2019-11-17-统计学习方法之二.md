---
layout:     post
title:      统计学习方法之二
subtitle:   统计学习及监督学习概论
date:       2019-11-17
author:     bjmsong
header-img: img/machineLearning/machineLearning.png
catalog: true
tags:
    - 机器学习
---
>本文将介绍统计学习及监督学习概论



### 统计学习（statistical learning）

- **定义：计算机基于数据构建概率统计模型，运用模型对数据进行预测与分析的学科**

- 基本假设：同类数据具有一定的统计规律性

- 步骤：

  - 得到一个有限的训练数据集合
  
  - 确定包含所有可能的模型的假设空间，即学习模型的集合，输入空间到输出空间映射的集合
  
  - 确定模型选择的准则，即学习的策略
  
  - 实现求解最优模型的算法，及学习的算法
    
    - 通过学习方法选择最优模型
    
  - 利用学习的最优模型对新数据进行预测或分析
  
    

#### 统计学习的分类

- 基本分类
  - 监督学习（supervised learning）
    - 从标注数据中学习预测模型，标注数据表示输入和输出的对应关系
    - 每个具体的输入是一个实例，通常由特征向量表示
    - 监督学习假设输入与输出变量X和Y遵循联合概率分布P(X,Y)。P(X,Y)表示分布函数，或分布密度函数。训练数据和测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的
  - **无监督学习**（unsupervised learning）
    
    - 无标注数据
    - 本质：学习数据中的统计规律或潜在结构
  - **强化学习**（reinforcement learning）
    
    - 指智能系统在与环境的连续互动中学习最优行为策略
    
    - 假设智能系统与环境的互动基于**马尔可夫决策过程**，智能系统能观测到的是与环境互动得到的数据序列
    
    - 本质：学习最优的序贯决策
    
    - 智能系统与环境的互动如图所示。在每一步t，智能系统从环境中观测到一个状态（state）$$s_t$$与一个奖励（reward）$$r_t$$，采取一个行动（action）$$a_t$$。环境根据智能系统选择的动作，决定下一步t+1的状态$$s_{t+1}$$与奖励$$r_{t+1}$$。要学习的策略表示为给定的状态下采取的行动。
    
    - **智能系统的目标不是短期奖励最大化，而是长期积累奖励的最大化​**
    
      <ul> 
      <li markdown="1"> 
      ![]({{site.baseurl}}/img/rl/四要素.png) 
      </li> 
      </ul> 
    
    - 强化学习的马尔可夫决策过程是状态、奖励、动作序列上的随机过程，由五元组<S,A,P,r,$$\gamma$$>组成：
    
      - S是有限状态的集合
    
      - A是有限动作的集合
    
      - P是状态转移概率（transition probability）函数：
    
        $$P(s'|s,a)=P(s_{t+1}=s'|s_t=s,a_t=a)$$
    
      - r是奖励函数：
      
        $$r(s,a)=E(r_{t+1}|s_t=s,a_t=a)$$
    
      - $$\gamma$$是衰减系数（discount factor）：$$\gamma\in[0,1]$$
    
  - 马尔可夫决策过程具有马尔可夫性，下一个状态只依赖于前一个状态与动作
    
  - 半监督学习（semi-supervised learning）
    - 少量标注数据，大量未标注数据
    - 利用未标注数据中的信息，辅助标注数据，进行监督学习
  - 主动学习（active learning）
    - 机器不断主动给出实例让教师进行标注，然后利用标注数据学习预测模型
    - 目标是找出对学习最有帮助的实例让教师标注，以较小的标注代价，达到较好的学习效果
  
- **按模型分类**
  
  - **概率模型和非概率模型**
    - 区别：模型的内在结构
      - 概率模型：一定可以表示为联合概率分布的形式，非概率模型不一定存在这样的联合概率分布
      - 条件概率分布`P（y|x）`和函数y=f(x)可以相互转化，条件概率分布最大化后得到函数，函数归一化后得到条件概率分布
    - 概率模型：概率图模型（朴素贝叶斯、隐马尔可夫、条件随机场）、决策树、概率潜在语义分析、潜在迪利克雷分配、高斯混合
    - 非概率模型：感知机、支持向量机、k近邻、AdaBoost、k均值、潜在语义分析、神经网络
  - 线性模型和非线性模型
    - 线性模型：函数是线性函数，感知机、线性支持向量机、k近邻、k均值、潜在语义分析
    - 非线性模型：核函数支持向量机、AdaBoost、神经网络、深度学习
  - **参数化模型和非参数化模型**
    - 参数化模型：假设模型参数的维度固定
    - 非参数化模型：假设模型参数的维度不固定或者无穷大，随着训练数据量的增加而不断增大
  
- 按算法分类
  - **在线学习（online learning）**
    - 每次接受一个样本，进行预测，之后学习模型，并不断重复该操作
    - 随机梯度下降
  - 批量学习（batch learning）
    - 一次接受所有数据，学习模型，之后进行预测
  
- 按技巧分类
  - **贝叶斯学习**
    - 利用贝叶斯定理，计算在给定数据条件下模型的条件概率，即后验概率
    - 贝叶斯学派vs频率学派
  - **核方法**
    
    

#### 统计学习方法三要素

- **模型（model set）：所要学习的条件概率分布或决策函数**
- **策略（objective function）：按照什么样的准则学习或选择最优的模型**
  
  - **损失函数**：度量模型预测的好坏
    - **最好与模型评价指标一致**
    - **需要连续可导**
    - 分类问题
      - 0-1损失
      - 对数损失
      - 交叉熵
    - 回归问题
      - 平方损失
      - 绝对损失
  - 风险函数：度量平均意义下模型预测的好坏
    - 经验风险：模型关于训练数据集的平均损失
    
      - 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于**极大似然估计**。
      - 容易过拟合
    
    - 结构风险：在经验风险上加上表示模型复杂度的正则化项
    
      - 当模型是条件概率分布，损失函数是对数损失函数，模型复杂度由模型的先验概率表示时，结构风险最小化就等价于**最大后验概率分布**。
      - 泛化能力较强
    
  
- **算法：学习模型的具体计算方法**
  
  - 最优化问题
  
  - 数值计算
  
    - 全局最优
  - 高效
    
  - 极少数问题有解析解
  
    
  

### 模型评估与模型选择

- 过拟合：模型过于复杂，对已知数据预测得很好，对未知数据预测得很差

<ul> 
<li markdown="1"> 
![]({{site.baseurl}}/img/machineLearning/模型复杂度.jpg) 
</li> 
</ul> 

- 正则化

  - 模型复杂度的单调递增函数，如模型参数的范数（L1/L2）

- 交叉验证
  - 如果数据充足：训练集、验证集、测试集
  - 如果数据不充足：交叉验证
    - 简单交叉，S折交叉，留一交叉
  - 有时间顺序的数据慎用交叉验证
  
- 泛化能力

  - 模型对未知数据的预测能力
  - 一般通过测试误差评价泛化能力

  

### 生成模型与判别模型

- 生成模型：由数据学习联合概率分布`P（X,Y）`，然后求出条件概率分布`P（Y|X）`作为预测

  - 朴素贝叶斯、隐马尔可夫
  - 收敛速度更快

- 判别模型：直接学习决策函数`f（X）`或者条件概率分布`P（Y|X）`作为预测

  - 准确率更高




### 监督学习应用

- 分类问题
  - 输出变量为有限个离散变量
  - 评价指标
    - 二分类：F1，Precision、Recall
- 标注问题
  - 输入与输出均为序列
  - 方法：隐马尔可夫、条件随机场
  - 应用：信息抽取、机器翻译
- 回归问题
  - 输出变量为连续变量


