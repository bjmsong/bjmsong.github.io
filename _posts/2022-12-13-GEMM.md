---
layout:     post
title:      GEMM
subtitle:   
date:       2022-12-13
author:     bjmsong
header-img: 
catalog: true
tags:
    - 模型优化与部署 
---
## Parallel Programming: Concepts and Practise, Bertil Schmidt
- 避免False Sharing
- 利用缓存（空间访问局部性）：矩阵转置
- 多线程：OpenMP
- SIMD

## 学习开源实现：OpenBLAS
- OpenBLAS项目与矩阵乘法优化 | AI 研习社
    - openblas作者：张先轶
    - https://www.leiphone.com/category/yanxishe/Puevv3ZWxn0heoEv.html
    - https://github.com/flame/blislab
    - https://github.com/flame/how-to-optimize-gemm
- https://github.com/xianyi/OpenBLAS
- https://zhuanlan.zhihu.com/p/65436463

## https://zhuanlan.zhihu.com/p/593537184?utm_medium=social&utm_oi=751534157867290624&utm_psn=1602249703252439040&utm_source=wechat_session&s_r=0

## 《Anatomy of High-Performance Matrix Multiplication》 GotoBlas作者写的

## how to optimize matrix multiply： ChatGPT
1. Loop unrolling: Instead of looping through each element of the matrices, loop unrolling involves processing multiple elements in each loop iteration. This can reduce the overhead of looping and increase the efficiency of the multiplication.

2. Cache blocking: Matrix multiplication requires accessing data from memory, which can be slow. Cache blocking involves breaking the matrices into smaller submatrices that fit into the cache. This allows the processor to access the data more quickly and can improve performance.

3. SIMD instructions: Single Instruction Multiple Data (SIMD) instructions can be used to perform the same operation on multiple data elements at once. This can improve performance by reducing the number of instructions that need to be executed.

4. Parallelization: Matrix multiplication can be parallelized by dividing the matrices into smaller pieces and assigning each piece to a different processor or thread. This can reduce the overall computation time by allowing multiple computations to be performed simultaneously.

5. Algorithm optimization: There are several algorithms for matrix multiplication, such as Strassen's algorithm and the Coppersmith-Winograd algorithm, that have been developed to reduce the number of multiplications and additions required for large matrices. Implementing these algorithms can improve performance for larger matrices.

Overall, the most effective optimization technique will depend on the specific characteristics of the matrices being multiplied and the hardware being used. A combination of these techniques may be necessary to achieve optimal performance.


## https://zhuanlan.zhihu.com/p/438173915

## 
- 通用矩阵乘是计算机视觉和自然语言处理模型中的主要的算子实现算法（例如，卷积，全连接，平均池化，注意力等算子均可以转换为 GEMM）
- 同时底层 GPU 和其他专有人工智能芯片 ASIC也针对矩阵乘的计算特点提供底层硬件计算单元的支持（例如 NVIDIA GPU 张量核（Tensor Core），Google TPU 脉动阵列的矩阵乘单元（Matrix Multiply Unit）等）

https://docs.nvidia.com/deeplearning/performance/dl-performance-convolutional/index.html
https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3
https://zhuanlan.zhihu.com/p/590555427
https://vaibhaw-vipul.medium.com/matrix-multiplication-optimizing-the-code-from-6-hours-to-1-sec-70889d33dcfa
https://blog.csdn.net/wwxy1995/article/details/114762108
https://www.cnblogs.com/sinkinben/p/16244156.html
https://renzibei.com/2021/06/30/optimize-gemm/
https://zhuanlan.zhihu.com/p/146250334
https://www.zhihu.com/question/41060378/answer/2645323107
https://www.zhihu.com/question/469164809/answer/1972397012
《On the Complexity of Matrix Multiplication》


https://www.zhihu.com/question/27872849

https://github.com/Maratyszcza/NNPACK